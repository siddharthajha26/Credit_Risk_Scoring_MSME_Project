{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79da4fa6-9016-4cd4-9044-d24e626a6589",
   "metadata": {},
   "source": [
    "# Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f092ca-5c4c-4797-8e49-d64dcaf92d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306636a3-eae9-458b-a05d-d456f968c7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>saving_ratio</th>\n",
       "      <th>debt_saving_ratio</th>\n",
       "      <th>default_flag</th>\n",
       "      <th>max_dpd_6_months</th>\n",
       "      <th>max_dpd_12_months</th>\n",
       "      <th>max_dpd_24_months</th>\n",
       "      <th>problematic_cheque_count</th>\n",
       "      <th>...</th>\n",
       "      <th>customer_profile_woe_encoded</th>\n",
       "      <th>customer_segment_woe_encoded</th>\n",
       "      <th>foreign_stakeholders_woe_encoded</th>\n",
       "      <th>other_debtors_woe_encoded</th>\n",
       "      <th>purpose_woe_encoded</th>\n",
       "      <th>revenue_range_woe_encoded</th>\n",
       "      <th>savings_woe_encoded</th>\n",
       "      <th>sector_woe_encoded</th>\n",
       "      <th>sector_risk_capped_0.99_woe_encoded</th>\n",
       "      <th>sme_history_begin_woe_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-09</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122209</td>\n",
       "      <td>0.814519</td>\n",
       "      <td>0.03295</td>\n",
       "      <td>-0.002220</td>\n",
       "      <td>-0.402431</td>\n",
       "      <td>-0.028904</td>\n",
       "      <td>-0.683867</td>\n",
       "      <td>-0.452792</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>-0.229130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-08-07</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122209</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.03295</td>\n",
       "      <td>-0.002220</td>\n",
       "      <td>-0.402431</td>\n",
       "      <td>-0.028904</td>\n",
       "      <td>0.269577</td>\n",
       "      <td>-0.452792</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.033635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-02-26</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122209</td>\n",
       "      <td>-1.161418</td>\n",
       "      <td>0.03295</td>\n",
       "      <td>-0.002220</td>\n",
       "      <td>0.611705</td>\n",
       "      <td>-0.058396</td>\n",
       "      <td>0.269577</td>\n",
       "      <td>-0.452792</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>-0.380269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122209</td>\n",
       "      <td>0.814519</td>\n",
       "      <td>0.03295</td>\n",
       "      <td>-0.519798</td>\n",
       "      <td>0.100762</td>\n",
       "      <td>-0.028904</td>\n",
       "      <td>0.269577</td>\n",
       "      <td>0.032576</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>-0.380269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-07-24</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122209</td>\n",
       "      <td>0.814519</td>\n",
       "      <td>0.03295</td>\n",
       "      <td>-0.002220</td>\n",
       "      <td>0.359709</td>\n",
       "      <td>-0.028904</td>\n",
       "      <td>0.269577</td>\n",
       "      <td>0.585677</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.033635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id        date  saving_ratio  debt_saving_ratio  default_flag  \\\n",
       "0           0   1  2020-12-09          0.24               0.22             0   \n",
       "1           1   2  2021-08-07          0.28               0.26             1   \n",
       "2           2   3  2023-02-26          0.42               0.40             0   \n",
       "3           3   4  2020-03-30          0.07               0.05             0   \n",
       "4           4   5  2021-07-24          0.13               0.10             1   \n",
       "\n",
       "   max_dpd_6_months  max_dpd_12_months  max_dpd_24_months  \\\n",
       "0                 0                  0                0.0   \n",
       "1                 0                 30                0.0   \n",
       "2                 0                 30                0.0   \n",
       "3                 0                 30                0.0   \n",
       "4                 0                 30                0.0   \n",
       "\n",
       "   problematic_cheque_count  ...  customer_profile_woe_encoded  \\\n",
       "0                         2  ...                     -0.122209   \n",
       "1                         0  ...                     -0.122209   \n",
       "2                         1  ...                     -0.122209   \n",
       "3                         0  ...                     -0.122209   \n",
       "4                         3  ...                     -0.122209   \n",
       "\n",
       "   customer_segment_woe_encoded  foreign_stakeholders_woe_encoded  \\\n",
       "0                      0.814519                           0.03295   \n",
       "1                      0.401000                           0.03295   \n",
       "2                     -1.161418                           0.03295   \n",
       "3                      0.814519                           0.03295   \n",
       "4                      0.814519                           0.03295   \n",
       "\n",
       "   other_debtors_woe_encoded  purpose_woe_encoded  revenue_range_woe_encoded  \\\n",
       "0                  -0.002220            -0.402431                  -0.028904   \n",
       "1                  -0.002220            -0.402431                  -0.028904   \n",
       "2                  -0.002220             0.611705                  -0.058396   \n",
       "3                  -0.519798             0.100762                  -0.028904   \n",
       "4                  -0.002220             0.359709                  -0.028904   \n",
       "\n",
       "   savings_woe_encoded  sector_woe_encoded  \\\n",
       "0            -0.683867           -0.452792   \n",
       "1             0.269577           -0.452792   \n",
       "2             0.269577           -0.452792   \n",
       "3             0.269577            0.032576   \n",
       "4             0.269577            0.585677   \n",
       "\n",
       "   sector_risk_capped_0.99_woe_encoded  sme_history_begin_woe_encoded  \n",
       "0                            -0.001891                      -0.229130  \n",
       "1                            -0.001891                       0.033635  \n",
       "2                            -0.001891                      -0.380269  \n",
       "3                            -0.001891                      -0.380269  \n",
       "4                            -0.001891                       0.033635  \n",
       "\n",
       "[5 rows x 179 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(\"C://Users/siddh/Credit_Risk_Scoring_MSME_Project/Dataset/MSME_clean_trasformed.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d29172-fc85-4d4e-8634-88a7ba53e505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                             0\n",
       "id                                     0\n",
       "date                                   0\n",
       "saving_ratio                           0\n",
       "debt_saving_ratio                      0\n",
       "                                      ..\n",
       "revenue_range_woe_encoded              0\n",
       "savings_woe_encoded                    0\n",
       "sector_woe_encoded                     0\n",
       "sector_risk_capped_0.99_woe_encoded    0\n",
       "sme_history_begin_woe_encoded          0\n",
       "Length: 179, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad719fe7-d1fc-4c27-929f-0daf2eb2af64",
   "metadata": {},
   "source": [
    "### Date-based Splitting:\n",
    "\n",
    "Uses a specified validation_date to split the dataset chronologically:\n",
    "\n",
    "Data before validation_date forms the training and test sets.\n",
    "\n",
    "Data on or after validation_date forms the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62437302-444e-4347-a9c4-4fda3c6c3175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"date\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7534ce62-f54c-4c69-972c-1219e04f57e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"date\"]=pd.to_datetime(df1[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d565dd-42ec-4b9b-9a6f-1afd58ecb396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"date\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78e58023-1bb5-451a-b1d8-3dd39f2ae2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date = \"2023-06-01\"\n",
    "format = \"%Y-%m-%d\"\n",
    "\n",
    "# Convert the string to a datetime object\n",
    "validation_date = datetime.strptime(date, format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2d7776-8486-45d9-a4b2-dcb424b29876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split  validation based on date\n",
    "train_test_data = df1[df1['date'] < validation_date]\n",
    "validation_data = df1[df1['date'] >= validation_date]\n",
    "y=train_test_data[\"default_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8551c50e-fb9b-4796-864c-a20f28c6c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(train_test_data,y,test_size = 0.3,random_state =42)\n",
    "# A regular train_test_split without stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fbcc6b1-273e-4376-a2c6-a85999aa718a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 179)\n",
      "(255, 179)\n",
      "(594,)\n",
      "(255,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf4b33-842f-4e6b-b258-311b408934c3",
   "metadata": {},
   "source": [
    "# Stratification\n",
    "Stratification ensures that the class distribution within the training, validation, and test sets mirrors the class distribution of the original dataset. For instance, if a dataset has 80% class A and 20% class B, a stratified split will ensure that each subset also maintains this 80:20 ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74e8c02-44b3-44dc-96b3-0a14f3d653f7",
   "metadata": {},
   "source": [
    "# Purpose:\n",
    "\n",
    "Divides the dataset into three subsets:\n",
    "\n",
    "Training set: Used to train the machine learning model.\n",
    "\n",
    "Test set: Used to evaluate the model's performance and tune parameters.\n",
    "\n",
    "Validation set: Used to perform a final evaluation after model selection and parameter tuning.\n",
    "\n",
    "### Stratified Sampling:\n",
    "\n",
    "Ensures that the distribution of months (year_month) is preserved in both train_data and test_data.\n",
    "\n",
    "Importance: Helps maintain the representative nature of the dataset, particularly useful for time-series data.\n",
    "\n",
    "Usage Considerations:\n",
    "\n",
    "### Validation Date: \n",
    "Critical for defining the point at which data transitions from training/test to validation.\n",
    "\n",
    "Random State: Controls the randomness of the split, influencing model performance evaluation consistency.\n",
    "### Validation Set Importance:\n",
    "\n",
    "Ensures an unbiased estimate of model performance on unseen data, crucial for assessing generalization capability before deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "defdf77e-b814-4608-a582-db2e9002bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d933caf-baee-42dd-8b0e-714f92dbb7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add year_month column for stratification\n",
    "df1['year_month'] = df1['date'].dt.to_period('M')\n",
    "X_train,X_test,y_train,y_test=train_test_split(train_test_data,y,test_size = 0.3,random_state =42,stratify=train_test_data['year_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c2de714-818c-4523-9e26-edd31cab3ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 179)\n",
      "(255, 179)\n",
      "(594,)\n",
      "(255,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d78f99-d18e-4a68-820d-0d0a529a101e",
   "metadata": {},
   "source": [
    "# Correlation and Multicollinearity\n",
    "If two or more independent variables are highly correlated there individual impact on predicting the output variable can not be determined accurately.\n",
    "Therefore it is necessary to eliminate columns from the dataset with high collinearity which can be decided based on a threshold value for cutoff.\n",
    "To avoid any loss of data we shall also store the elimated variables in a list of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c21bccf7-dc69-4ea4-b945-66acae24ac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     saving_ratio  debt_saving_ratio  \\\n",
      "saving_ratio                             1.000000           0.999991   \n",
      "debt_saving_ratio                        0.999991           1.000000   \n",
      "default_flag                             0.496870           0.496898   \n",
      "max_dpd_6_months                         0.177233           0.177075   \n",
      "max_dpd_12_months                        0.164969           0.164640   \n",
      "...                                           ...                ...   \n",
      "revenue_range_woe_encoded               -0.016365          -0.016460   \n",
      "savings_woe_encoded                      0.055741           0.055597   \n",
      "sector_woe_encoded                       0.034854           0.034780   \n",
      "sector_risk_capped_0.99_woe_encoded           NaN                NaN   \n",
      "sme_history_begin_woe_encoded            0.044506           0.044584   \n",
      "\n",
      "                                     default_flag  max_dpd_6_months  \\\n",
      "saving_ratio                             0.496870          0.177233   \n",
      "debt_saving_ratio                        0.496898          0.177075   \n",
      "default_flag                             1.000000          0.311805   \n",
      "max_dpd_6_months                         0.311805          1.000000   \n",
      "max_dpd_12_months                        0.291156          0.925874   \n",
      "...                                           ...               ...   \n",
      "revenue_range_woe_encoded                0.038908          0.026484   \n",
      "savings_woe_encoded                      0.189874          0.020629   \n",
      "sector_woe_encoded                       0.153617          0.024154   \n",
      "sector_risk_capped_0.99_woe_encoded           NaN               NaN   \n",
      "sme_history_begin_woe_encoded            0.135404          0.035085   \n",
      "\n",
      "                                     max_dpd_12_months  max_dpd_24_months  \\\n",
      "saving_ratio                                  0.164969           0.174247   \n",
      "debt_saving_ratio                             0.164640           0.174036   \n",
      "default_flag                                  0.291156           0.293453   \n",
      "max_dpd_6_months                              0.925874           0.941142   \n",
      "max_dpd_12_months                             1.000000           0.967968   \n",
      "...                                                ...                ...   \n",
      "revenue_range_woe_encoded                     0.019824           0.030234   \n",
      "savings_woe_encoded                           0.022724           0.021575   \n",
      "sector_woe_encoded                            0.012659           0.008467   \n",
      "sector_risk_capped_0.99_woe_encoded                NaN                NaN   \n",
      "sme_history_begin_woe_encoded                 0.026285           0.030683   \n",
      "\n",
      "                                     problematic_cheque_count  \\\n",
      "saving_ratio                                         0.006978   \n",
      "debt_saving_ratio                                    0.006880   \n",
      "default_flag                                         0.019054   \n",
      "max_dpd_6_months                                    -0.003176   \n",
      "max_dpd_12_months                                   -0.007856   \n",
      "...                                                       ...   \n",
      "revenue_range_woe_encoded                           -0.001765   \n",
      "savings_woe_encoded                                  0.067135   \n",
      "sector_woe_encoded                                  -0.000844   \n",
      "sector_risk_capped_0.99_woe_encoded                       NaN   \n",
      "sme_history_begin_woe_encoded                        0.000545   \n",
      "\n",
      "                                     duration_in_month  credit_amount  \\\n",
      "saving_ratio                                  0.114467       0.049358   \n",
      "debt_saving_ratio                             0.114448       0.049400   \n",
      "default_flag                                  0.214927       0.154739   \n",
      "max_dpd_6_months                              0.090556       0.057565   \n",
      "max_dpd_12_months                             0.080387       0.044653   \n",
      "...                                                ...            ...   \n",
      "revenue_range_woe_encoded                     0.156237       0.325838   \n",
      "savings_woe_encoded                          -0.014225      -0.024044   \n",
      "sector_woe_encoded                            0.287125       0.312319   \n",
      "sector_risk_capped_0.99_woe_encoded                NaN            NaN   \n",
      "sme_history_begin_woe_encoded                -0.083760      -0.033273   \n",
      "\n",
      "                                     installment_as_income_perc  ...  \\\n",
      "saving_ratio                                           0.064761  ...   \n",
      "debt_saving_ratio                                      0.064786  ...   \n",
      "default_flag                                           0.072404  ...   \n",
      "max_dpd_6_months                                       0.036876  ...   \n",
      "max_dpd_12_months                                      0.029260  ...   \n",
      "...                                                         ...  ...   \n",
      "revenue_range_woe_encoded                              0.011504  ...   \n",
      "savings_woe_encoded                                   -0.022904  ...   \n",
      "sector_woe_encoded                                     0.049692  ...   \n",
      "sector_risk_capped_0.99_woe_encoded                         NaN  ...   \n",
      "sme_history_begin_woe_encoded                         -0.083973  ...   \n",
      "\n",
      "                                     customer_profile_woe_encoded  \\\n",
      "saving_ratio                                             0.008510   \n",
      "debt_saving_ratio                                        0.008700   \n",
      "default_flag                                             0.113304   \n",
      "max_dpd_6_months                                         0.019965   \n",
      "max_dpd_12_months                                        0.008609   \n",
      "...                                                           ...   \n",
      "revenue_range_woe_encoded                                0.048774   \n",
      "savings_woe_encoded                                      0.003725   \n",
      "sector_woe_encoded                                       0.079822   \n",
      "sector_risk_capped_0.99_woe_encoded                           NaN   \n",
      "sme_history_begin_woe_encoded                           -0.002930   \n",
      "\n",
      "                                     customer_segment_woe_encoded  \\\n",
      "saving_ratio                                             0.169840   \n",
      "debt_saving_ratio                                        0.169889   \n",
      "default_flag                                             0.350442   \n",
      "max_dpd_6_months                                         0.100414   \n",
      "max_dpd_12_months                                        0.098176   \n",
      "...                                                           ...   \n",
      "revenue_range_woe_encoded                                0.013626   \n",
      "savings_woe_encoded                                      0.227965   \n",
      "sector_woe_encoded                                       0.067249   \n",
      "sector_risk_capped_0.99_woe_encoded                           NaN   \n",
      "sme_history_begin_woe_encoded                            0.108927   \n",
      "\n",
      "                                     foreign_stakeholders_woe_encoded  \\\n",
      "saving_ratio                                                 0.058597   \n",
      "debt_saving_ratio                                            0.058748   \n",
      "default_flag                                                 0.082079   \n",
      "max_dpd_6_months                                             0.040011   \n",
      "max_dpd_12_months                                            0.040735   \n",
      "...                                                               ...   \n",
      "revenue_range_woe_encoded                                    0.044666   \n",
      "savings_woe_encoded                                          0.006452   \n",
      "sector_woe_encoded                                           0.106837   \n",
      "sector_risk_capped_0.99_woe_encoded                               NaN   \n",
      "sme_history_begin_woe_encoded                               -0.025280   \n",
      "\n",
      "                                     other_debtors_woe_encoded  \\\n",
      "saving_ratio                                          0.032221   \n",
      "debt_saving_ratio                                     0.032214   \n",
      "default_flag                                          0.081446   \n",
      "max_dpd_6_months                                      0.023239   \n",
      "max_dpd_12_months                                     0.007198   \n",
      "...                                                        ...   \n",
      "revenue_range_woe_encoded                             0.103833   \n",
      "savings_woe_encoded                                  -0.032999   \n",
      "sector_woe_encoded                                    0.127954   \n",
      "sector_risk_capped_0.99_woe_encoded                        NaN   \n",
      "sme_history_begin_woe_encoded                         0.035502   \n",
      "\n",
      "                                     purpose_woe_encoded  \\\n",
      "saving_ratio                                    0.108129   \n",
      "debt_saving_ratio                               0.108103   \n",
      "default_flag                                    0.181984   \n",
      "max_dpd_6_months                                0.061643   \n",
      "max_dpd_12_months                               0.066989   \n",
      "...                                                  ...   \n",
      "revenue_range_woe_encoded                      -0.030262   \n",
      "savings_woe_encoded                             0.077896   \n",
      "sector_woe_encoded                              0.026922   \n",
      "sector_risk_capped_0.99_woe_encoded                  NaN   \n",
      "sme_history_begin_woe_encoded                   0.066164   \n",
      "\n",
      "                                     revenue_range_woe_encoded  \\\n",
      "saving_ratio                                         -0.016365   \n",
      "debt_saving_ratio                                    -0.016460   \n",
      "default_flag                                          0.038908   \n",
      "max_dpd_6_months                                      0.026484   \n",
      "max_dpd_12_months                                     0.019824   \n",
      "...                                                        ...   \n",
      "revenue_range_woe_encoded                             1.000000   \n",
      "savings_woe_encoded                                   0.018937   \n",
      "sector_woe_encoded                                    0.232749   \n",
      "sector_risk_capped_0.99_woe_encoded                        NaN   \n",
      "sme_history_begin_woe_encoded                         0.077584   \n",
      "\n",
      "                                     savings_woe_encoded  sector_woe_encoded  \\\n",
      "saving_ratio                                    0.055741            0.034854   \n",
      "debt_saving_ratio                               0.055597            0.034780   \n",
      "default_flag                                    0.189874            0.153617   \n",
      "max_dpd_6_months                                0.020629            0.024154   \n",
      "max_dpd_12_months                               0.022724            0.012659   \n",
      "...                                                  ...                 ...   \n",
      "revenue_range_woe_encoded                       0.018937            0.232749   \n",
      "savings_woe_encoded                             1.000000           -0.009222   \n",
      "sector_woe_encoded                             -0.009222            1.000000   \n",
      "sector_risk_capped_0.99_woe_encoded                  NaN                 NaN   \n",
      "sme_history_begin_woe_encoded                   0.104347           -0.055214   \n",
      "\n",
      "                                     sector_risk_capped_0.99_woe_encoded  \\\n",
      "saving_ratio                                                         NaN   \n",
      "debt_saving_ratio                                                    NaN   \n",
      "default_flag                                                         NaN   \n",
      "max_dpd_6_months                                                     NaN   \n",
      "max_dpd_12_months                                                    NaN   \n",
      "...                                                                  ...   \n",
      "revenue_range_woe_encoded                                            NaN   \n",
      "savings_woe_encoded                                                  NaN   \n",
      "sector_woe_encoded                                                   NaN   \n",
      "sector_risk_capped_0.99_woe_encoded                                  NaN   \n",
      "sme_history_begin_woe_encoded                                        NaN   \n",
      "\n",
      "                                     sme_history_begin_woe_encoded  \n",
      "saving_ratio                                              0.044506  \n",
      "debt_saving_ratio                                         0.044584  \n",
      "default_flag                                              0.135404  \n",
      "max_dpd_6_months                                          0.035085  \n",
      "max_dpd_12_months                                         0.026285  \n",
      "...                                                            ...  \n",
      "revenue_range_woe_encoded                                 0.077584  \n",
      "savings_woe_encoded                                       0.104347  \n",
      "sector_woe_encoded                                       -0.055214  \n",
      "sector_risk_capped_0.99_woe_encoded                            NaN  \n",
      "sme_history_begin_woe_encoded                             1.000000  \n",
      "\n",
      "[175 rows x 175 columns]\n"
     ]
    }
   ],
   "source": [
    "data.drop([\"Unnamed: 0\",\"id\",\"year_month\"],axis =1,inplace = True)\n",
    "correlation_matrix=data.corr(numeric_only=True)\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Since our dataset has 179 columns,plotting the correlation matrix is not useful "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba3c26-ad15-4f8b-bd50-075dfab23b57",
   "metadata": {},
   "source": [
    "As in the following code we have removed the correlated columns from the data\n",
    "\n",
    "Similar operations need to be done for training,test and validation data to remove any collinear columns\n",
    "\n",
    "Removing collinearity makes the model more reliable,stable,efficient and realistic.\n",
    "\n",
    "The following code removes the threshold values based on 2 parametres\n",
    "\n",
    "1 Data\n",
    "\n",
    "2 Correlation Threshold\n",
    "\n",
    "Removes highly correlated variables above the given threshold.\n",
    "   \n",
    "Returns\n",
    "    reduced_df (DataFrame): Dataset after removing correlated variables\n",
    "    eliminated_columns (list): List of removed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6d3e18c-b221-4924-93bf-4cd414b05f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_correlated_variables(df, threshold):\n",
    "    \n",
    "    # Compute correlation matrix (absolute values)\n",
    "    corr_matrix = data.corr().abs()\n",
    "\n",
    "    # Upper triangle matrix (to avoid duplicate pairs)\n",
    "    upper_tri = corr_matrix.where(\n",
    "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool) #used to extract the upper triangular portion of an array, setting all elements below a specified diagonal to zero. \n",
    "    ) # k  An optional integer offset for the diagonal(-1 Include diagnal and elements below ,0- includes main diagonal,1- Exclude main diagonal and Include elements above the main diagonal)\n",
    "\n",
    "    # Identify columns to drop\n",
    "    eliminated_columns = [\n",
    "        column for column in upper_tri.columns\n",
    "        if any(upper_tri[column] > threshold)\n",
    "    ]\n",
    "\n",
    "    # Create reduced dataset\n",
    "    reduced_df = df.drop(columns=eliminated_columns)\n",
    "\n",
    "    return reduced_df, eliminated_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d17005e4-d5a1-4846-9655-3b2c801e39e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminated columns: ['debt_saving_ratio', 'max_dpd_12_months', 'max_dpd_24_months', 'year', 'EBITDA_capped_0.99', 'Int_coverage_ratio_capped_0.99', 'Net_Profit_Margin_capped_0.99', 'ROA_capped_0.99', 'ROE_capped_0.99', 'Revenue_Growth_Rate_capped_0.99', 'average_credit_duration_capped_0.99', 'credit_amount_capped_0.99', 'credits_this_bank_capped_0.99', 'debt_saving_ratio_capped_0.99', 'default_flag_capped_0.99', 'duration_in_month_capped_0.99', 'installment_as_income_perc_capped_0.99', 'max_dpd_12_months_capped_0.99', 'max_dpd_24_months_capped_0.99', 'max_dpd_6_months_capped_0.99', 'people_under_maintenance_capped_0.99', 'present_res_since_capped_0.99', 'problematic_cheque_count_capped_0.99', 'saving_ratio_capped_0.99', 'boxcox_id', 'boxcox_saving_ratio', 'boxcox_duration_in_month', 'boxcox_installment_as_income_perc', 'boxcox_present_res_since', 'boxcox_average_credit_duration', 'boxcox_credits_this_bank', 'boxcox_people_under_maintenance', 'boxcox_EBITDA', 'boxcox_month', 'boxcox_EBITDA_capped_0.99', 'boxcox_average_credit_duration_capped_0.99', 'boxcox_credit_amount_capped_0.99', 'boxcox_credits_this_bank_capped_0.99', 'boxcox_duration_in_month_capped_0.99', 'boxcox_id_capped_0.99', 'boxcox_installment_as_income_perc_capped_0.99', 'boxcox_people_under_maintenance_capped_0.99', 'boxcox_present_res_since_capped_0.99', 'boxcox_saving_ratio_capped_0.99', 'yj_Unnamed: 0', 'yj_id', 'yj_saving_ratio', 'yj_debt_saving_ratio', 'yj_default_flag', 'yj_max_dpd_6_months', 'yj_max_dpd_12_months', 'yj_max_dpd_24_months', 'yj_problematic_cheque_count', 'yj_duration_in_month', 'yj_credit_amount', 'yj_installment_as_income_perc', 'yj_present_res_since', 'yj_average_credit_duration', 'yj_credits_this_bank', 'yj_people_under_maintenance', 'yj_sector_risk', 'yj_EBITDA', 'yj_ROE', 'yj_ROA', 'yj_Revenue_Growth_Rate', 'yj_Int_coverage_ratio', 'yj_Net_Profit_Margin', 'yj_year', 'yj_month', 'yj_EBITDA_capped_0.99', 'yj_Int_coverage_ratio_capped_0.99', 'yj_Net_Profit_Margin_capped_0.99', 'yj_ROA_capped_0.99', 'yj_ROE_capped_0.99', 'yj_Revenue_Growth_Rate_capped_0.99', 'yj_average_credit_duration_capped_0.99', 'yj_credit_amount_capped_0.99', 'yj_credits_this_bank_capped_0.99', 'yj_debt_saving_ratio_capped_0.99', 'yj_default_flag_capped_0.99', 'yj_duration_in_month_capped_0.99', 'yj_id_capped_0.99', 'yj_installment_as_income_perc_capped_0.99', 'yj_max_dpd_12_months_capped_0.99', 'yj_max_dpd_24_months_capped_0.99', 'yj_max_dpd_6_months_capped_0.99', 'yj_people_under_maintenance_capped_0.99', 'yj_present_res_since_capped_0.99', 'yj_problematic_cheque_count_capped_0.99', 'yj_saving_ratio_capped_0.99', 'yj_sector_risk_capped_0.99', 'foreign_stakeholders_mean_encoded', 'revenue_range_mean_encoded', 'business_type_woe_encoded', 'credit_history_woe_encoded', 'customer_profile_woe_encoded', 'customer_segment_woe_encoded', 'foreign_stakeholders_woe_encoded', 'other_debtors_woe_encoded', 'purpose_woe_encoded', 'revenue_range_woe_encoded', 'savings_woe_encoded', 'sector_woe_encoded', 'sme_history_begin_woe_encoded']\n",
      "Reduced dataset shape: (1000, 72)\n"
     ]
    }
   ],
   "source": [
    "# Function call on the dataset\n",
    "credit_risk_data = data.copy()\n",
    "threshold = 0.9\n",
    "reduced_df, eliminated_columns = eliminate_correlated_variables(credit_risk_data, threshold)\n",
    "\n",
    "print(\"Eliminated columns:\", eliminated_columns)\n",
    "print(\"Reduced dataset shape:\", reduced_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14060b91-712b-4424-af1e-01c0447e6bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 72)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.shape # The number of columns have reduced to 72 from 179 intitially as the correlated columns hab=ve been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1adc609-f432-4e48-aca9-470a45416d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>saving_ratio</th>\n",
       "      <th>default_flag</th>\n",
       "      <th>max_dpd_6_months</th>\n",
       "      <th>problematic_cheque_count</th>\n",
       "      <th>duration_in_month</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>installment_as_income_perc</th>\n",
       "      <th>present_res_since</th>\n",
       "      <th>average_credit_duration</th>\n",
       "      <th>...</th>\n",
       "      <th>credit_history_mean_encoded</th>\n",
       "      <th>customer_profile_mean_encoded</th>\n",
       "      <th>customer_segment_mean_encoded</th>\n",
       "      <th>other_debtors_mean_encoded</th>\n",
       "      <th>purpose_mean_encoded</th>\n",
       "      <th>savings_mean_encoded</th>\n",
       "      <th>sector_mean_encoded</th>\n",
       "      <th>sector_risk_capped_0.99_mean_encoded</th>\n",
       "      <th>sme_history_begin_mean_encoded</th>\n",
       "      <th>sector_risk_capped_0.99_woe_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-09</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170648</td>\n",
       "      <td>0.275184</td>\n",
       "      <td>0.492701</td>\n",
       "      <td>0.299890</td>\n",
       "      <td>0.221429</td>\n",
       "      <td>0.174863</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.252964</td>\n",
       "      <td>-0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-08-07</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>5951</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318868</td>\n",
       "      <td>0.275184</td>\n",
       "      <td>0.390335</td>\n",
       "      <td>0.299890</td>\n",
       "      <td>0.221429</td>\n",
       "      <td>0.359867</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.306785</td>\n",
       "      <td>-0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-26</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2096</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170648</td>\n",
       "      <td>0.275184</td>\n",
       "      <td>0.116751</td>\n",
       "      <td>0.299890</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.359867</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>-0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>7882</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318868</td>\n",
       "      <td>0.275184</td>\n",
       "      <td>0.492701</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.320442</td>\n",
       "      <td>0.359867</td>\n",
       "      <td>0.306034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>-0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-24</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>4870</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.275184</td>\n",
       "      <td>0.492701</td>\n",
       "      <td>0.299890</td>\n",
       "      <td>0.380342</td>\n",
       "      <td>0.359867</td>\n",
       "      <td>0.435065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.306785</td>\n",
       "      <td>-0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2023-08-14</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1736</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318868</td>\n",
       "      <td>0.275184</td>\n",
       "      <td>0.116751</td>\n",
       "      <td>0.299890</td>\n",
       "      <td>0.320442</td>\n",
       "      <td>0.359867</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>-0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3857</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318868</td>\n",
       "      <td>0.275184</td>\n",
       "      <td>0.492701</td>\n",
       "      <td>0.299890</td>\n",
       "      <td>0.165049</td>\n",
       "      <td>0.359867</td>\n",
       "      <td>0.306034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.306785</td>\n",
       "      <td>-0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>804</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318868</td>\n",
       "      <td>0.275184</td>\n",
       "      <td>0.116751</td>\n",
       "      <td>0.299890</td>\n",
       "      <td>0.221429</td>\n",
       "      <td>0.359867</td>\n",
       "      <td>0.307229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.252964</td>\n",
       "      <td>-0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>1845</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318868</td>\n",
       "      <td>0.275184</td>\n",
       "      <td>0.492701</td>\n",
       "      <td>0.299890</td>\n",
       "      <td>0.221429</td>\n",
       "      <td>0.359867</td>\n",
       "      <td>0.435065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.306785</td>\n",
       "      <td>-0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2021-11-18</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>4576</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170648</td>\n",
       "      <td>0.275184</td>\n",
       "      <td>0.390335</td>\n",
       "      <td>0.299890</td>\n",
       "      <td>0.165049</td>\n",
       "      <td>0.330097</td>\n",
       "      <td>0.307229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>-0.001891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  saving_ratio  default_flag  max_dpd_6_months  \\\n",
       "0   2020-12-09          0.24             0                 0   \n",
       "1   2021-08-07          0.28             1                 0   \n",
       "2   2023-02-26          0.42             0                 0   \n",
       "3   2020-03-30          0.07             0                 0   \n",
       "4   2021-07-24          0.13             1                 0   \n",
       "..         ...           ...           ...               ...   \n",
       "995 2023-08-14          0.29             0                 0   \n",
       "996 2023-01-12          0.06             0                 0   \n",
       "997 2023-07-28          0.39             0                 0   \n",
       "998 2023-07-31          0.31             1                 0   \n",
       "999 2021-11-18          0.32             0                 0   \n",
       "\n",
       "     problematic_cheque_count  duration_in_month  credit_amount  \\\n",
       "0                           2                  6           1169   \n",
       "1                           0                 48           5951   \n",
       "2                           1                 12           2096   \n",
       "3                           0                 42           7882   \n",
       "4                           3                 24           4870   \n",
       "..                        ...                ...            ...   \n",
       "995                         3                 12           1736   \n",
       "996                         0                 30           3857   \n",
       "997                         3                 12            804   \n",
       "998                         2                 45           1845   \n",
       "999                         2                 45           4576   \n",
       "\n",
       "     installment_as_income_perc  present_res_since  average_credit_duration  \\\n",
       "0                             4                  4                       67   \n",
       "1                             2                  2                       22   \n",
       "2                             2                  3                       49   \n",
       "3                             2                  4                       45   \n",
       "4                             3                  4                       53   \n",
       "..                          ...                ...                      ...   \n",
       "995                           3                  4                       31   \n",
       "996                           4                  4                       40   \n",
       "997                           4                  4                       38   \n",
       "998                           4                  4                       23   \n",
       "999                           3                  4                       27   \n",
       "\n",
       "     ...  credit_history_mean_encoded  customer_profile_mean_encoded  \\\n",
       "0    ...                     0.170648                       0.275184   \n",
       "1    ...                     0.318868                       0.275184   \n",
       "2    ...                     0.170648                       0.275184   \n",
       "3    ...                     0.318868                       0.275184   \n",
       "4    ...                     0.318182                       0.275184   \n",
       "..   ...                          ...                            ...   \n",
       "995  ...                     0.318868                       0.275184   \n",
       "996  ...                     0.318868                       0.275184   \n",
       "997  ...                     0.318868                       0.275184   \n",
       "998  ...                     0.318868                       0.275184   \n",
       "999  ...                     0.170648                       0.275184   \n",
       "\n",
       "     customer_segment_mean_encoded  other_debtors_mean_encoded  \\\n",
       "0                         0.492701                    0.299890   \n",
       "1                         0.390335                    0.299890   \n",
       "2                         0.116751                    0.299890   \n",
       "3                         0.492701                    0.192308   \n",
       "4                         0.492701                    0.299890   \n",
       "..                             ...                         ...   \n",
       "995                       0.116751                    0.299890   \n",
       "996                       0.492701                    0.299890   \n",
       "997                       0.116751                    0.299890   \n",
       "998                       0.492701                    0.299890   \n",
       "999                       0.390335                    0.299890   \n",
       "\n",
       "     purpose_mean_encoded  savings_mean_encoded  sector_mean_encoded  \\\n",
       "0                0.221429              0.174863             0.212766   \n",
       "1                0.221429              0.359867             0.212766   \n",
       "2                0.440000              0.359867             0.212766   \n",
       "3                0.320442              0.359867             0.306034   \n",
       "4                0.380342              0.359867             0.435065   \n",
       "..                    ...                   ...                  ...   \n",
       "995              0.320442              0.359867             0.212766   \n",
       "996              0.165049              0.359867             0.306034   \n",
       "997              0.221429              0.359867             0.307229   \n",
       "998              0.221429              0.359867             0.435065   \n",
       "999              0.165049              0.330097             0.307229   \n",
       "\n",
       "     sector_risk_capped_0.99_mean_encoded  sme_history_begin_mean_encoded  \\\n",
       "0                                     NaN                        0.252964   \n",
       "1                                     NaN                        0.306785   \n",
       "2                                     NaN                        0.224138   \n",
       "3                                     NaN                        0.224138   \n",
       "4                                     NaN                        0.306785   \n",
       "..                                    ...                             ...   \n",
       "995                                   NaN                        0.224138   \n",
       "996                                   NaN                        0.306785   \n",
       "997                                   NaN                        0.252964   \n",
       "998                                   NaN                        0.306785   \n",
       "999                                   NaN                        0.370968   \n",
       "\n",
       "     sector_risk_capped_0.99_woe_encoded  \n",
       "0                              -0.001891  \n",
       "1                              -0.001891  \n",
       "2                              -0.001891  \n",
       "3                              -0.001891  \n",
       "4                              -0.001891  \n",
       "..                                   ...  \n",
       "995                            -0.001891  \n",
       "996                            -0.001891  \n",
       "997                            -0.001891  \n",
       "998                            -0.001891  \n",
       "999                            -0.001891  \n",
       "\n",
       "[1000 rows x 72 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22efd3cb-8d56-4fc0-acef-64637d1a76f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(594, 179)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = X_train.copy()\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c625cbf6-3b3b-4a03-bf69-dd8f6b4ec9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminated columns: ['debt_saving_ratio', 'max_dpd_12_months', 'max_dpd_24_months', 'year', 'EBITDA_capped_0.99', 'Int_coverage_ratio_capped_0.99', 'Net_Profit_Margin_capped_0.99', 'ROA_capped_0.99', 'ROE_capped_0.99', 'Revenue_Growth_Rate_capped_0.99', 'average_credit_duration_capped_0.99', 'credit_amount_capped_0.99', 'credits_this_bank_capped_0.99', 'debt_saving_ratio_capped_0.99', 'default_flag_capped_0.99', 'duration_in_month_capped_0.99', 'installment_as_income_perc_capped_0.99', 'max_dpd_12_months_capped_0.99', 'max_dpd_24_months_capped_0.99', 'max_dpd_6_months_capped_0.99', 'people_under_maintenance_capped_0.99', 'present_res_since_capped_0.99', 'problematic_cheque_count_capped_0.99', 'saving_ratio_capped_0.99', 'boxcox_id', 'boxcox_saving_ratio', 'boxcox_duration_in_month', 'boxcox_credit_amount', 'boxcox_installment_as_income_perc', 'boxcox_present_res_since', 'boxcox_average_credit_duration', 'boxcox_credits_this_bank', 'boxcox_people_under_maintenance', 'boxcox_EBITDA', 'boxcox_month', 'boxcox_EBITDA_capped_0.99', 'boxcox_average_credit_duration_capped_0.99', 'boxcox_credit_amount_capped_0.99', 'boxcox_credits_this_bank_capped_0.99', 'boxcox_duration_in_month_capped_0.99', 'boxcox_id_capped_0.99', 'boxcox_installment_as_income_perc_capped_0.99', 'boxcox_people_under_maintenance_capped_0.99', 'boxcox_present_res_since_capped_0.99', 'boxcox_saving_ratio_capped_0.99', 'yj_Unnamed: 0', 'yj_id', 'yj_saving_ratio', 'yj_debt_saving_ratio', 'yj_default_flag', 'yj_max_dpd_6_months', 'yj_max_dpd_12_months', 'yj_max_dpd_24_months', 'yj_problematic_cheque_count', 'yj_duration_in_month', 'yj_credit_amount', 'yj_installment_as_income_perc', 'yj_present_res_since', 'yj_average_credit_duration', 'yj_credits_this_bank', 'yj_people_under_maintenance', 'yj_sector_risk', 'yj_EBITDA', 'yj_ROE', 'yj_ROA', 'yj_Revenue_Growth_Rate', 'yj_Int_coverage_ratio', 'yj_Net_Profit_Margin', 'yj_year', 'yj_month', 'yj_EBITDA_capped_0.99', 'yj_Int_coverage_ratio_capped_0.99', 'yj_Net_Profit_Margin_capped_0.99', 'yj_ROA_capped_0.99', 'yj_ROE_capped_0.99', 'yj_Revenue_Growth_Rate_capped_0.99', 'yj_average_credit_duration_capped_0.99', 'yj_credit_amount_capped_0.99', 'yj_credits_this_bank_capped_0.99', 'yj_debt_saving_ratio_capped_0.99', 'yj_default_flag_capped_0.99', 'yj_duration_in_month_capped_0.99', 'yj_id_capped_0.99', 'yj_installment_as_income_perc_capped_0.99', 'yj_max_dpd_12_months_capped_0.99', 'yj_max_dpd_24_months_capped_0.99', 'yj_max_dpd_6_months_capped_0.99', 'yj_people_under_maintenance_capped_0.99', 'yj_present_res_since_capped_0.99', 'yj_problematic_cheque_count_capped_0.99', 'yj_saving_ratio_capped_0.99', 'yj_sector_risk_capped_0.99', 'other_debtors_none', 'sector_Telecommunications', 'credit_history_mean_encoded', 'customer_profile_mean_encoded', 'customer_segment_mean_encoded', 'foreign_stakeholders_mean_encoded', 'revenue_range_mean_encoded', 'savings_mean_encoded', 'sector_mean_encoded', 'sme_history_begin_mean_encoded', 'business_type_woe_encoded', 'credit_history_woe_encoded', 'customer_profile_woe_encoded', 'customer_segment_woe_encoded', 'foreign_stakeholders_woe_encoded', 'other_debtors_woe_encoded', 'purpose_woe_encoded', 'revenue_range_woe_encoded', 'savings_woe_encoded', 'sector_woe_encoded', 'sme_history_begin_woe_encoded']\n",
      "Reduced dataset shape: (594, 66)\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.7\n",
    "train_data_corr_eliminated, eliminated_columns = eliminate_correlated_variables(train_data, threshold)\n",
    "\n",
    "print(\"Eliminated columns:\", eliminated_columns)\n",
    "print(\"Reduced dataset shape:\", train_data_corr_eliminated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5aeda650-d15b-4358-aa0f-76eb21a10151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                0\n",
       "id                                        0\n",
       "date                                      0\n",
       "saving_ratio                              0\n",
       "default_flag                              0\n",
       "                                       ... \n",
       "business_type_mean_encoded                0\n",
       "other_debtors_mean_encoded                0\n",
       "purpose_mean_encoded                      0\n",
       "sector_risk_capped_0.99_mean_encoded    594\n",
       "sector_risk_capped_0.99_woe_encoded       0\n",
       "Length: 66, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_corr_eliminated.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dcf0fdb-4203-4425-ad04-7d50819efe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                             0\n",
       "id                                     0\n",
       "date                                   0\n",
       "saving_ratio                           0\n",
       "default_flag                           0\n",
       "                                      ..\n",
       "sme_history_begin_new company          0\n",
       "business_type_mean_encoded             0\n",
       "other_debtors_mean_encoded             0\n",
       "purpose_mean_encoded                   0\n",
       "sector_risk_capped_0.99_woe_encoded    0\n",
       "Length: 65, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since there is only one column with NaN values in the train_data_corr_eliminated, We shall drop the column\n",
    "train_data_corr_eliminated.drop(\"sector_risk_capped_0.99_mean_encoded\",axis =1,inplace =True)\n",
    "train_data_corr_eliminated.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ac0bc9d-7eb9-49e6-ba0e-2055ac8ac43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(594, 65)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_corr_eliminated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5e05c9f-da39-4344-b6b8-1bad8892e22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                             0\n",
       "id                                     0\n",
       "date                                   0\n",
       "saving_ratio                           0\n",
       "default_flag                           0\n",
       "                                      ..\n",
       "sme_history_begin_new company          0\n",
       "business_type_mean_encoded             0\n",
       "other_debtors_mean_encoded             0\n",
       "purpose_mean_encoded                   0\n",
       "sector_risk_capped_0.99_woe_encoded    0\n",
       "Length: 65, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data_corr_eliminated = validation_data[train_data_corr_eliminated.columns]\n",
    "validation_data_corr_eliminated.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f9a8a82-10d0-4579-ba11-6351aeef1494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 65)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data_corr_eliminated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9355fbdf-c5b7-4b31-9d0a-0d43464439e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=X_test.copy()\n",
    "test_data_corr_eliminated=test_data[train_data_corr_eliminated.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c98f39ae-39c3-462c-bbf1-637cd78e42a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 65)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_corr_eliminated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22dd241-4603-424c-80a7-e7c177cfbc6b",
   "metadata": {},
   "source": [
    "As we can see we have successfully created a validation data based on cut-off date parameter out of the existing dataset.\n",
    "We have eliminated correlated variables from the dataset using the np.triu function and reduced the dataset size.\n",
    "Similarly we have exucuted the same function to remove the correlated variables in the stratified train,test and split data.\n",
    "As we can observe the num of rows for train+test =999 which is as it should be after excluding the header along with 67 columns\n",
    "whoch is infact a comparatively smaller data to be used in training machine learning model.\n",
    "This approach is very usefull specially when our dataset is large in size and we have correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a1d29f-9c46-4e52-92da-7ac9dcafbaf1",
   "metadata": {},
   "source": [
    "# Information_Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f1b8a-07ea-45bd-a1df-bfbc6a18c7fa",
   "metadata": {},
   "source": [
    "Information Value (IV) measures the predictive power of an independent variable in relation to the dependent variable (usually a binary outcome like default vs. non-default). It quantifies the strength of association between a variable and the outcome by assessing the difference in distributions between \"good\" and \"bad\" categories. Higher IV values indicate stronger predictive power of the variable and hence aids feature selection for the best model performance.IV distinguishes predictors in terms of prediction strength of distinguishing defaulters from non defaulters and model improvement removes weak predictors to enhance model performance. Preditive power of a variable is based on its distribution between the good and bad segments.\n",
    "\n",
    "IV helps in variable selection by identifying variables that are most predictive of the outcome, making it a crucial metric in feature selection and credit scoring applications.\n",
    "\n",
    "To calculate Information Value we will define the IV_calc Function with three  Parameters:\n",
    "\n",
    "- data (DataFrame): The dataset.\n",
    "    \n",
    " - default_flag (str or numeric): The name of the default flag variable.\n",
    "    \n",
    "- variable (str): The name of the variable for which IV is to be calculated.\n",
    "\n",
    "Returns:\n",
    "float: The calculated Information Value (IV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "274766d4-ca38-4b4c-82e8-648285187a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# User Defined function to aid reusability on each of the features in the dataset we define function IV_calc as below\n",
    "def IV_calc(data, default_flag, variable):\n",
    "   \n",
    "    # Split the dataset into \"good\" (good) and \"bad\" (bad) based on the default_flag variable\n",
    "    good = data[data[default_flag] == 0]\n",
    "    bad = data[data[default_flag] == 1]\n",
    "    \n",
    "    # Compute the frequency of each unique value of variable in both good and bad datasets (x and y respectively).\n",
    "    x = good[variable].value_counts().to_frame().reset_index() # Creates a Dataframe x with Variable name and there values counts for good(0's) \n",
    "    x.columns = ['Var1', 'Freq.x']# Assigns the columns name to the columns\n",
    "    y = bad[variable].value_counts().to_frame().reset_index()# Creates a Dataframe y with Variable name and there values counts for bad(1's)\n",
    "    y.columns = ['Var1', 'Freq.y']# Assigns the columns name to the columns\n",
    "\n",
    "    print(\"\\nCounts for variable\", variable, \"in good data:\")\n",
    "    print(x)\n",
    "    print(\"\\nCounts for variable\", variable, \"in bad data:\")\n",
    "    print(y)\n",
    "    # Merge the frequency counts (x and y) based on the unique values of variable\n",
    "    merged = pd.merge(x, y, on=\"Var1\", how=\"outer\") # merges the two dataframes on a aommin key var1 \n",
    "    # Compute the percentage of each unique value within good and bad datasets.\n",
    "    merged['percentx'] = merged['Freq.x'] / merged['Freq.x'].sum() # percentage of goods(0's) out of total(good's+bad's) for all Freq.x values\n",
    "    merged['percenty'] = merged['Freq.y'] / merged['Freq.y'].sum() # percentage of bads(0's) out of total(good's+bad's) for all Freq.x values\n",
    "\n",
    "    print(\"\\nMerged data:\")\n",
    "    print(merged)\n",
    "    # Calculate the Information Value (IV) using the formula.\n",
    "    merged['IV'] = (merged['percentx'] - merged['percenty']) * np.log(merged['percentx'] / merged['percenty'])\n",
    "    # Summarize the IV for the variable.\n",
    "    IV_RESULT = merged['IV'].sum() \n",
    "\n",
    "    print(\"\\nIV for variable\", variable, \":\", IV_RESULT)\n",
    "\n",
    "    return IV_RESULT # Returns the calculated Information Value (IV) for the specified variable\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe949e0-adcd-4c08-88c8-e70850d760da",
   "metadata": {},
   "source": [
    "Calculate the Information Value (IV) for each variable in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - data (DataFrame): The dataset containing variables for IV calculation\n",
    "    - default_flag (str or numeric): The name of the default flag variable.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: DataFrame containing variables and their corresponding IVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fb15087-db62-4796-8283-63f6ac27c0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counts for variable Unnamed: 0 in good data:\n",
      "     Var1  Freq.x\n",
      "0     455       1\n",
      "1      25       1\n",
      "2     836       1\n",
      "3      82       1\n",
      "4     432       1\n",
      "..    ...     ...\n",
      "409     8       1\n",
      "410   650       1\n",
      "411   567       1\n",
      "412   453       1\n",
      "413   342       1\n",
      "\n",
      "[414 rows x 2 columns]\n",
      "\n",
      "Counts for variable Unnamed: 0 in bad data:\n",
      "     Var1  Freq.y\n",
      "0     789       1\n",
      "1     405       1\n",
      "2     557       1\n",
      "3     849       1\n",
      "4     790       1\n",
      "..    ...     ...\n",
      "175   935       1\n",
      "176   981       1\n",
      "177   364       1\n",
      "178   862       1\n",
      "179   315       1\n",
      "\n",
      "[180 rows x 2 columns]\n",
      "\n",
      "Merged data:\n",
      "     Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0       1     NaN     1.0       NaN  0.005556\n",
      "1       2     1.0     NaN  0.002415       NaN\n",
      "2       3     1.0     NaN  0.002415       NaN\n",
      "3       4     NaN     1.0       NaN  0.005556\n",
      "4       7     1.0     NaN  0.002415       NaN\n",
      "..    ...     ...     ...       ...       ...\n",
      "589   987     1.0     NaN  0.002415       NaN\n",
      "590   992     1.0     NaN  0.002415       NaN\n",
      "591   994     1.0     NaN  0.002415       NaN\n",
      "592   996     1.0     NaN  0.002415       NaN\n",
      "593   999     1.0     NaN  0.002415       NaN\n",
      "\n",
      "[594 rows x 5 columns]\n",
      "\n",
      "IV for variable Unnamed: 0 : 0.0\n",
      "\n",
      "Counts for variable id in good data:\n",
      "     Var1  Freq.x\n",
      "0     456       1\n",
      "1      26       1\n",
      "2     837       1\n",
      "3      83       1\n",
      "4     433       1\n",
      "..    ...     ...\n",
      "409     9       1\n",
      "410   651       1\n",
      "411   568       1\n",
      "412   454       1\n",
      "413   343       1\n",
      "\n",
      "[414 rows x 2 columns]\n",
      "\n",
      "Counts for variable id in bad data:\n",
      "     Var1  Freq.y\n",
      "0     790       1\n",
      "1     406       1\n",
      "2     558       1\n",
      "3     850       1\n",
      "4     791       1\n",
      "..    ...     ...\n",
      "175   936       1\n",
      "176   982       1\n",
      "177   365       1\n",
      "178   863       1\n",
      "179   316       1\n",
      "\n",
      "[180 rows x 2 columns]\n",
      "\n",
      "Merged data:\n",
      "     Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0       2     NaN     1.0       NaN  0.005556\n",
      "1       3     1.0     NaN  0.002415       NaN\n",
      "2       4     1.0     NaN  0.002415       NaN\n",
      "3       5     NaN     1.0       NaN  0.005556\n",
      "4       8     1.0     NaN  0.002415       NaN\n",
      "..    ...     ...     ...       ...       ...\n",
      "589   988     1.0     NaN  0.002415       NaN\n",
      "590   993     1.0     NaN  0.002415       NaN\n",
      "591   995     1.0     NaN  0.002415       NaN\n",
      "592   997     1.0     NaN  0.002415       NaN\n",
      "593  1000     1.0     NaN  0.002415       NaN\n",
      "\n",
      "[594 rows x 5 columns]\n",
      "\n",
      "IV for variable id : 0.0\n",
      "\n",
      "Counts for variable date in good data:\n",
      "          Var1  Freq.x\n",
      "0   2021-07-07       4\n",
      "1   2021-01-20       4\n",
      "2   2020-06-13       3\n",
      "3   2020-03-13       3\n",
      "4   2022-07-09       3\n",
      "..         ...     ...\n",
      "350 2020-09-07       1\n",
      "351 2022-01-20       1\n",
      "352 2021-04-25       1\n",
      "353 2021-12-12       1\n",
      "354 2021-04-28       1\n",
      "\n",
      "[355 rows x 2 columns]\n",
      "\n",
      "Counts for variable date in bad data:\n",
      "          Var1  Freq.y\n",
      "0   2021-08-07       3\n",
      "1   2023-05-03       2\n",
      "2   2020-04-04       2\n",
      "3   2022-04-15       2\n",
      "4   2020-02-12       2\n",
      "..         ...     ...\n",
      "166 2020-11-14       1\n",
      "167 2021-09-30       1\n",
      "168 2022-07-10       1\n",
      "169 2020-06-13       1\n",
      "170 2023-04-25       1\n",
      "\n",
      "[171 rows x 2 columns]\n",
      "\n",
      "Merged data:\n",
      "          Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   2020-01-04     1.0     1.0  0.002415  0.005556\n",
      "1   2020-01-06     1.0     NaN  0.002415       NaN\n",
      "2   2020-01-07     NaN     1.0       NaN  0.005556\n",
      "3   2020-01-08     1.0     NaN  0.002415       NaN\n",
      "4   2020-01-09     1.0     NaN  0.002415       NaN\n",
      "..         ...     ...     ...       ...       ...\n",
      "476 2023-05-18     NaN     1.0       NaN  0.005556\n",
      "477 2023-05-20     1.0     NaN  0.002415       NaN\n",
      "478 2023-05-25     1.0     NaN  0.002415       NaN\n",
      "479 2023-05-28     1.0     NaN  0.002415       NaN\n",
      "480 2023-05-29     1.0     NaN  0.002415       NaN\n",
      "\n",
      "[481 rows x 5 columns]\n",
      "\n",
      "IV for variable date : 0.13108142926376515\n",
      "\n",
      "Counts for variable saving_ratio in good data:\n",
      "    Var1  Freq.x\n",
      "0   0.21      14\n",
      "1   0.40      14\n",
      "2   0.41      13\n",
      "3   0.46      12\n",
      "4   0.45      12\n",
      "5   0.14      12\n",
      "6   0.32      12\n",
      "7   0.24      11\n",
      "8   0.18      11\n",
      "9   0.34      11\n",
      "10  0.29      10\n",
      "11  0.42      10\n",
      "12  0.35      10\n",
      "13  0.36      10\n",
      "14  0.15      10\n",
      "15  0.25       9\n",
      "16  0.09       9\n",
      "17  0.19       9\n",
      "18  0.23       9\n",
      "19  0.38       9\n",
      "20  0.51       9\n",
      "21  0.22       9\n",
      "22  0.11       9\n",
      "23  0.27       8\n",
      "24  0.17       8\n",
      "25  0.31       8\n",
      "26  0.07       8\n",
      "27  0.37       8\n",
      "28  0.43       8\n",
      "29  0.33       7\n",
      "30  0.12       7\n",
      "31  0.04       7\n",
      "32  0.44       7\n",
      "33  0.03       7\n",
      "34  0.13       7\n",
      "35  0.49       7\n",
      "36  0.05       6\n",
      "37  0.26       6\n",
      "38  0.48       6\n",
      "39  0.39       6\n",
      "40  0.06       6\n",
      "41  0.50       6\n",
      "42  0.30       6\n",
      "43  0.47       5\n",
      "44  0.08       5\n",
      "45  0.28       5\n",
      "46  0.16       4\n",
      "47  0.20       4\n",
      "48  0.10       4\n",
      "49  0.02       2\n",
      "50  0.52       2\n",
      "\n",
      "Counts for variable saving_ratio in bad data:\n",
      "    Var1  Freq.y\n",
      "0   0.26       6\n",
      "1   0.05       5\n",
      "2   0.71       4\n",
      "3   0.85       4\n",
      "4   0.98       4\n",
      "..   ...     ...\n",
      "82  0.95       1\n",
      "83  0.64       1\n",
      "84  0.99       1\n",
      "85  0.63       1\n",
      "86  0.86       1\n",
      "\n",
      "[87 rows x 2 columns]\n",
      "\n",
      "Merged data:\n",
      "    Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.02     2.0     2.0  0.004831  0.011111\n",
      "1   0.03     7.0     1.0  0.016908  0.005556\n",
      "2   0.04     7.0     1.0  0.016908  0.005556\n",
      "3   0.05     6.0     5.0  0.014493  0.027778\n",
      "4   0.06     6.0     2.0  0.014493  0.011111\n",
      "..   ...     ...     ...       ...       ...\n",
      "90  0.98     NaN     4.0       NaN  0.022222\n",
      "91  0.99     NaN     1.0       NaN  0.005556\n",
      "92  1.00     NaN     3.0       NaN  0.016667\n",
      "93  1.01     NaN     4.0       NaN  0.022222\n",
      "94  1.02     NaN     1.0       NaN  0.005556\n",
      "\n",
      "[95 rows x 5 columns]\n",
      "\n",
      "IV for variable saving_ratio : 0.488495497742935\n",
      "\n",
      "Counts for variable max_dpd_6_months in good data:\n",
      "   Var1  Freq.x\n",
      "0     0     414\n",
      "\n",
      "Counts for variable max_dpd_6_months in bad data:\n",
      "   Var1  Freq.y\n",
      "0     0     159\n",
      "1    30      21\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0     0   414.0     159       1.0  0.883333\n",
      "1    30     NaN      21       NaN  0.116667\n",
      "\n",
      "IV for variable max_dpd_6_months : 0.014472809011497534\n",
      "\n",
      "Counts for variable problematic_cheque_count in good data:\n",
      "   Var1  Freq.x\n",
      "0     0     117\n",
      "1     3     106\n",
      "2     1      96\n",
      "3     2      95\n",
      "\n",
      "Counts for variable problematic_cheque_count in bad data:\n",
      "   Var1  Freq.y\n",
      "0     3      58\n",
      "1     0      49\n",
      "2     2      37\n",
      "3     1      36\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0     0     117      49  0.282609  0.272222\n",
      "1     1      96      36  0.231884  0.200000\n",
      "2     2      95      37  0.229469  0.205556\n",
      "3     3     106      58  0.256039  0.322222\n",
      "\n",
      "IV for variable problematic_cheque_count : 0.02295330429825658\n",
      "\n",
      "Counts for variable duration_in_month in good data:\n",
      "    Var1  Freq.x\n",
      "0     12      83\n",
      "1     24      76\n",
      "2     18      45\n",
      "3      6      36\n",
      "4     15      32\n",
      "5     36      29\n",
      "6      9      22\n",
      "7     30      19\n",
      "8     10      11\n",
      "9     48      10\n",
      "10    21       9\n",
      "11    20       5\n",
      "12     8       5\n",
      "13     7       4\n",
      "14    60       4\n",
      "15    27       3\n",
      "16    42       3\n",
      "17    11       3\n",
      "18    13       3\n",
      "19    39       2\n",
      "20    14       2\n",
      "21    28       2\n",
      "22    33       1\n",
      "23    16       1\n",
      "24    45       1\n",
      "25    54       1\n",
      "26    26       1\n",
      "27     4       1\n",
      "\n",
      "Counts for variable duration_in_month in bad data:\n",
      "    Var1  Freq.y\n",
      "0     12      37\n",
      "1     24      31\n",
      "2     18      23\n",
      "3     36      20\n",
      "4     48      18\n",
      "5     15      11\n",
      "6     30       9\n",
      "7      9       6\n",
      "8      6       5\n",
      "9     21       5\n",
      "10    27       4\n",
      "11    42       2\n",
      "12    45       2\n",
      "13    60       2\n",
      "14    10       1\n",
      "15    20       1\n",
      "16    40       1\n",
      "17    16       1\n",
      "18    28       1\n",
      "\n",
      "Merged data:\n",
      "    Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0      4     1.0     NaN  0.002415       NaN\n",
      "1      6    36.0     5.0  0.086957  0.027778\n",
      "2      7     4.0     NaN  0.009662       NaN\n",
      "3      8     5.0     NaN  0.012077       NaN\n",
      "4      9    22.0     6.0  0.053140  0.033333\n",
      "5     10    11.0     1.0  0.026570  0.005556\n",
      "6     11     3.0     NaN  0.007246       NaN\n",
      "7     12    83.0    37.0  0.200483  0.205556\n",
      "8     13     3.0     NaN  0.007246       NaN\n",
      "9     14     2.0     NaN  0.004831       NaN\n",
      "10    15    32.0    11.0  0.077295  0.061111\n",
      "11    16     1.0     1.0  0.002415  0.005556\n",
      "12    18    45.0    23.0  0.108696  0.127778\n",
      "13    20     5.0     1.0  0.012077  0.005556\n",
      "14    21     9.0     5.0  0.021739  0.027778\n",
      "15    24    76.0    31.0  0.183575  0.172222\n",
      "16    26     1.0     NaN  0.002415       NaN\n",
      "17    27     3.0     4.0  0.007246  0.022222\n",
      "18    28     2.0     1.0  0.004831  0.005556\n",
      "19    30    19.0     9.0  0.045894  0.050000\n",
      "20    33     1.0     NaN  0.002415       NaN\n",
      "21    36    29.0    20.0  0.070048  0.111111\n",
      "22    39     2.0     NaN  0.004831       NaN\n",
      "23    40     NaN     1.0       NaN  0.005556\n",
      "24    42     3.0     2.0  0.007246  0.011111\n",
      "25    45     1.0     2.0  0.002415  0.011111\n",
      "26    48    10.0    18.0  0.024155  0.100000\n",
      "27    54     1.0     NaN  0.002415       NaN\n",
      "28    60     4.0     2.0  0.009662  0.011111\n",
      "\n",
      "IV for variable duration_in_month : 0.2856145880727991\n",
      "\n",
      "Counts for variable credit_amount in good data:\n",
      "     Var1  Freq.x\n",
      "0    1126       2\n",
      "1    2578       2\n",
      "2    1374       2\n",
      "3    1449       2\n",
      "4    1597       2\n",
      "..    ...     ...\n",
      "391  2764       1\n",
      "392  1495       1\n",
      "393  3059       1\n",
      "394  7476       1\n",
      "395  3213       1\n",
      "\n",
      "[396 rows x 2 columns]\n",
      "\n",
      "Counts for variable credit_amount in bad data:\n",
      "      Var1  Freq.y\n",
      "0     1442       2\n",
      "1     1282       2\n",
      "2     5998       1\n",
      "3     1922       1\n",
      "4     1188       1\n",
      "..     ...     ...\n",
      "173   2439       1\n",
      "174  14782       1\n",
      "175  10127       1\n",
      "176   1501       1\n",
      "177   2746       1\n",
      "\n",
      "[178 rows x 2 columns]\n",
      "\n",
      "Merged data:\n",
      "      Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0      250     1.0     NaN  0.002415       NaN\n",
      "1      276     1.0     NaN  0.002415       NaN\n",
      "2      385     1.0     NaN  0.002415       NaN\n",
      "3      409     1.0     NaN  0.002415       NaN\n",
      "4      433     NaN     1.0       NaN  0.005556\n",
      "..     ...     ...     ...       ...       ...\n",
      "559  14318     NaN     1.0       NaN  0.005556\n",
      "560  14421     NaN     1.0       NaN  0.005556\n",
      "561  14782     NaN     1.0       NaN  0.005556\n",
      "562  15653     1.0     NaN  0.002415       NaN\n",
      "563  15857     1.0     NaN  0.002415       NaN\n",
      "\n",
      "[564 rows x 5 columns]\n",
      "\n",
      "IV for variable credit_amount : 0.026154151203276212\n",
      "\n",
      "Counts for variable installment_as_income_perc in good data:\n",
      "   Var1  Freq.x\n",
      "0     4     189\n",
      "1     2      94\n",
      "2     3      67\n",
      "3     1      64\n",
      "\n",
      "Counts for variable installment_as_income_perc in bad data:\n",
      "   Var1  Freq.y\n",
      "0     4      91\n",
      "1     2      40\n",
      "2     3      31\n",
      "3     1      18\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0     1      64      18  0.154589  0.100000\n",
      "1     2      94      40  0.227053  0.222222\n",
      "2     3      67      31  0.161836  0.172222\n",
      "3     4     189      91  0.456522  0.505556\n",
      "\n",
      "IV for variable installment_as_income_perc : 0.029531731652834983\n",
      "\n",
      "Counts for variable present_res_since in good data:\n",
      "   Var1  Freq.x\n",
      "0     4     174\n",
      "1     2     124\n",
      "2     3      59\n",
      "3     1      57\n",
      "\n",
      "Counts for variable present_res_since in bad data:\n",
      "   Var1  Freq.y\n",
      "0     4      66\n",
      "1     2      60\n",
      "2     3      31\n",
      "3     1      23\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0     1      57      23  0.137681  0.127778\n",
      "1     2     124      60  0.299517  0.333333\n",
      "2     3      59      31  0.142512  0.172222\n",
      "3     4     174      66  0.420290  0.366667\n",
      "\n",
      "IV for variable present_res_since : 0.01730166736752146\n",
      "\n",
      "Counts for variable average_credit_duration in good data:\n",
      "    Var1  Freq.x\n",
      "0     35      22\n",
      "1     26      21\n",
      "2     36      20\n",
      "3     28      19\n",
      "4     27      18\n",
      "5     40      16\n",
      "6     32      15\n",
      "7     31      15\n",
      "8     37      14\n",
      "9     23      14\n",
      "10    24      13\n",
      "11    29      12\n",
      "12    34      12\n",
      "13    30      11\n",
      "14    38      11\n",
      "15    22      10\n",
      "16    46      10\n",
      "17    39      10\n",
      "18    25      10\n",
      "19    41      10\n",
      "20    33       9\n",
      "21    45       9\n",
      "22    43       8\n",
      "23    21       8\n",
      "24    49       7\n",
      "25    63       7\n",
      "26    42       7\n",
      "27    44       6\n",
      "28    50       6\n",
      "29    54       5\n",
      "30    47       5\n",
      "31    48       5\n",
      "32    20       5\n",
      "33    55       4\n",
      "34    51       4\n",
      "35    52       4\n",
      "36    61       3\n",
      "37    60       3\n",
      "38    57       3\n",
      "39    58       3\n",
      "40    64       3\n",
      "41    62       2\n",
      "42    74       2\n",
      "43    67       2\n",
      "44    59       2\n",
      "45    66       2\n",
      "46    75       2\n",
      "47    65       2\n",
      "48    68       1\n",
      "49    19       1\n",
      "50    53       1\n",
      "\n",
      "Counts for variable average_credit_duration in bad data:\n",
      "    Var1  Freq.y\n",
      "0     28      12\n",
      "1     25      11\n",
      "2     23      11\n",
      "3     29      11\n",
      "4     26      10\n",
      "5     33       8\n",
      "6     34       7\n",
      "7     24       7\n",
      "8     37       6\n",
      "9     31       6\n",
      "10    22       6\n",
      "11    30       6\n",
      "12    27       5\n",
      "13    42       5\n",
      "14    32       5\n",
      "15    35       5\n",
      "16    40       4\n",
      "17    44       4\n",
      "18    53       4\n",
      "19    20       3\n",
      "20    39       3\n",
      "21    57       3\n",
      "22    47       3\n",
      "23    41       3\n",
      "24    36       3\n",
      "25    55       3\n",
      "26    61       2\n",
      "27    54       2\n",
      "28    45       2\n",
      "29    60       2\n",
      "30    66       2\n",
      "31    21       2\n",
      "32    46       2\n",
      "33    38       2\n",
      "34    59       1\n",
      "35    68       1\n",
      "36    74       1\n",
      "37    65       1\n",
      "38    58       1\n",
      "39    63       1\n",
      "40    52       1\n",
      "41    49       1\n",
      "42    43       1\n",
      "43    51       1\n",
      "\n",
      "Merged data:\n",
      "    Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0     19       1     NaN  0.002415       NaN\n",
      "1     20       5     3.0  0.012077  0.016667\n",
      "2     21       8     2.0  0.019324  0.011111\n",
      "3     22      10     6.0  0.024155  0.033333\n",
      "4     23      14    11.0  0.033816  0.061111\n",
      "5     24      13     7.0  0.031401  0.038889\n",
      "6     25      10    11.0  0.024155  0.061111\n",
      "7     26      21    10.0  0.050725  0.055556\n",
      "8     27      18     5.0  0.043478  0.027778\n",
      "9     28      19    12.0  0.045894  0.066667\n",
      "10    29      12    11.0  0.028986  0.061111\n",
      "11    30      11     6.0  0.026570  0.033333\n",
      "12    31      15     6.0  0.036232  0.033333\n",
      "13    32      15     5.0  0.036232  0.027778\n",
      "14    33       9     8.0  0.021739  0.044444\n",
      "15    34      12     7.0  0.028986  0.038889\n",
      "16    35      22     5.0  0.053140  0.027778\n",
      "17    36      20     3.0  0.048309  0.016667\n",
      "18    37      14     6.0  0.033816  0.033333\n",
      "19    38      11     2.0  0.026570  0.011111\n",
      "20    39      10     3.0  0.024155  0.016667\n",
      "21    40      16     4.0  0.038647  0.022222\n",
      "22    41      10     3.0  0.024155  0.016667\n",
      "23    42       7     5.0  0.016908  0.027778\n",
      "24    43       8     1.0  0.019324  0.005556\n",
      "25    44       6     4.0  0.014493  0.022222\n",
      "26    45       9     2.0  0.021739  0.011111\n",
      "27    46      10     2.0  0.024155  0.011111\n",
      "28    47       5     3.0  0.012077  0.016667\n",
      "29    48       5     NaN  0.012077       NaN\n",
      "30    49       7     1.0  0.016908  0.005556\n",
      "31    50       6     NaN  0.014493       NaN\n",
      "32    51       4     1.0  0.009662  0.005556\n",
      "33    52       4     1.0  0.009662  0.005556\n",
      "34    53       1     4.0  0.002415  0.022222\n",
      "35    54       5     2.0  0.012077  0.011111\n",
      "36    55       4     3.0  0.009662  0.016667\n",
      "37    57       3     3.0  0.007246  0.016667\n",
      "38    58       3     1.0  0.007246  0.005556\n",
      "39    59       2     1.0  0.004831  0.005556\n",
      "40    60       3     2.0  0.007246  0.011111\n",
      "41    61       3     2.0  0.007246  0.011111\n",
      "42    62       2     NaN  0.004831       NaN\n",
      "43    63       7     1.0  0.016908  0.005556\n",
      "44    64       3     NaN  0.007246       NaN\n",
      "45    65       2     1.0  0.004831  0.005556\n",
      "46    66       2     2.0  0.004831  0.011111\n",
      "47    67       2     NaN  0.004831       NaN\n",
      "48    68       1     1.0  0.002415  0.005556\n",
      "49    74       2     1.0  0.004831  0.005556\n",
      "50    75       2     NaN  0.004831       NaN\n",
      "\n",
      "IV for variable average_credit_duration : 0.3436781803002259\n",
      "\n",
      "Counts for variable credits_this_bank in good data:\n",
      "   Var1  Freq.x\n",
      "0     1     251\n",
      "1     2     144\n",
      "2     3      15\n",
      "3     4       4\n",
      "\n",
      "Counts for variable credits_this_bank in bad data:\n",
      "   Var1  Freq.y\n",
      "0     1     119\n",
      "1     2      56\n",
      "2     3       4\n",
      "3     4       1\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0     1     251     119  0.606280  0.661111\n",
      "1     2     144      56  0.347826  0.311111\n",
      "2     3      15       4  0.036232  0.022222\n",
      "3     4       4       1  0.009662  0.005556\n",
      "\n",
      "IV for variable credits_this_bank : 0.017963822018170105\n",
      "\n",
      "Counts for variable people_under_maintenance in good data:\n",
      "   Var1  Freq.x\n",
      "0    10     352\n",
      "1    20      62\n",
      "\n",
      "Counts for variable people_under_maintenance in bad data:\n",
      "   Var1  Freq.y\n",
      "0    10     152\n",
      "1    20      28\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0    10     352     152  0.850242  0.844444\n",
      "1    20      62      28  0.149758  0.155556\n",
      "\n",
      "IV for variable people_under_maintenance : 0.0002598306080112073\n",
      "\n",
      "Counts for variable sector_risk in good data:\n",
      "   Var1  Freq.x\n",
      "0     0      62\n",
      "1     2      56\n",
      "2     3      54\n",
      "3     4      53\n",
      "4     7      51\n",
      "5     5      50\n",
      "6     1      48\n",
      "7     6      40\n",
      "\n",
      "Counts for variable sector_risk in bad data:\n",
      "   Var1  Freq.y\n",
      "0     7      28\n",
      "1     3      26\n",
      "2     6      24\n",
      "3     9      24\n",
      "4     4      23\n",
      "5    10      21\n",
      "6     8      21\n",
      "7     5      13\n",
      "\n",
      "Merged data:\n",
      "    Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0      0    62.0     NaN  0.149758       NaN\n",
      "1      1    48.0     NaN  0.115942       NaN\n",
      "2      2    56.0     NaN  0.135266       NaN\n",
      "3      3    54.0    26.0  0.130435  0.144444\n",
      "4      4    53.0    23.0  0.128019  0.127778\n",
      "5      5    50.0    13.0  0.120773  0.072222\n",
      "6      6    40.0    24.0  0.096618  0.133333\n",
      "7      7    51.0    28.0  0.123188  0.155556\n",
      "8      8     NaN    21.0       NaN  0.116667\n",
      "9      9     NaN    24.0       NaN  0.133333\n",
      "10    10     NaN    21.0       NaN  0.116667\n",
      "\n",
      "IV for variable sector_risk : 0.04576896030584574\n",
      "\n",
      "Counts for variable EBITDA in good data:\n",
      "     Var1  Freq.x\n",
      "0     142       4\n",
      "1     405       3\n",
      "2     637       3\n",
      "3     426       3\n",
      "4     478       3\n",
      "..    ...     ...\n",
      "332   790       1\n",
      "333    16       1\n",
      "334   210       1\n",
      "335   436       1\n",
      "336   120       1\n",
      "\n",
      "[337 rows x 2 columns]\n",
      "\n",
      "Counts for variable EBITDA in bad data:\n",
      "     Var1  Freq.y\n",
      "0     167       3\n",
      "1     202       2\n",
      "2     250       2\n",
      "3     258       2\n",
      "4     646       2\n",
      "..    ...     ...\n",
      "151   483       1\n",
      "152   679       1\n",
      "153   741       1\n",
      "154   448       1\n",
      "155   777       1\n",
      "\n",
      "[156 rows x 2 columns]\n",
      "\n",
      "Merged data:\n",
      "     Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0      12     1.0     NaN  0.002415       NaN\n",
      "1      13     2.0     NaN  0.004831       NaN\n",
      "2      16     1.0     NaN  0.002415       NaN\n",
      "3      18     1.0     NaN  0.002415       NaN\n",
      "4      21     2.0     NaN  0.004831       NaN\n",
      "..    ...     ...     ...       ...       ...\n",
      "430   962     NaN     1.0       NaN  0.005556\n",
      "431   973     NaN     1.0       NaN  0.005556\n",
      "432   981     NaN     1.0       NaN  0.005556\n",
      "433   983     NaN     1.0       NaN  0.005556\n",
      "434   994     NaN     1.0       NaN  0.005556\n",
      "\n",
      "[435 rows x 5 columns]\n",
      "\n",
      "IV for variable EBITDA : 0.20446139742010827\n",
      "\n",
      "Counts for variable ROE in good data:\n",
      "     Var1  Freq.x\n",
      "0      41       9\n",
      "1      43       8\n",
      "2      39       7\n",
      "3      81       7\n",
      "4      79       7\n",
      "..    ...     ...\n",
      "105    53       1\n",
      "106   -10       1\n",
      "107    59       1\n",
      "108    91       1\n",
      "109    52       1\n",
      "\n",
      "[110 rows x 2 columns]\n",
      "\n",
      "Counts for variable ROE in bad data:\n",
      "    Var1  Freq.y\n",
      "0    121       6\n",
      "1     47       6\n",
      "2     50       5\n",
      "3    134       5\n",
      "4     55       4\n",
      "..   ...     ...\n",
      "92    64       1\n",
      "93   140       1\n",
      "94   135       1\n",
      "95    83       1\n",
      "96    72       1\n",
      "\n",
      "[97 rows x 2 columns]\n",
      "\n",
      "Merged data:\n",
      "     Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0     -10     1.0     NaN  0.002415       NaN\n",
      "1      -9     4.0     NaN  0.009662       NaN\n",
      "2      -8     7.0     NaN  0.016908       NaN\n",
      "3      -7     3.0     NaN  0.007246       NaN\n",
      "4      -6     2.0     NaN  0.004831       NaN\n",
      "..    ...     ...     ...       ...       ...\n",
      "138   143     NaN     2.0       NaN  0.011111\n",
      "139   145     NaN     1.0       NaN  0.005556\n",
      "140   147     NaN     2.0       NaN  0.011111\n",
      "141   149     NaN     1.0       NaN  0.005556\n",
      "142   150     NaN     2.0       NaN  0.011111\n",
      "\n",
      "[143 rows x 5 columns]\n",
      "\n",
      "IV for variable ROE : 0.33665692251902535\n",
      "\n",
      "Counts for variable ROA in good data:\n",
      "    Var1  Freq.x\n",
      "0     61      10\n",
      "1     98       9\n",
      "2     85       8\n",
      "3     71       8\n",
      "4     16       8\n",
      "..   ...     ...\n",
      "95    42       1\n",
      "96    82       1\n",
      "97    36       1\n",
      "98    20       1\n",
      "99    22       1\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Counts for variable ROA in bad data:\n",
      "    Var1  Freq.y\n",
      "0    101       5\n",
      "1     80       5\n",
      "2    116       4\n",
      "3    131       4\n",
      "4     54       4\n",
      "..   ...     ...\n",
      "82    58       1\n",
      "83   105       1\n",
      "84    81       1\n",
      "85   134       1\n",
      "86   104       1\n",
      "\n",
      "[87 rows x 2 columns]\n",
      "\n",
      "Merged data:\n",
      "     Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0       0     4.0     NaN  0.009662       NaN\n",
      "1       1     4.0     NaN  0.009662       NaN\n",
      "2       2     2.0     NaN  0.004831       NaN\n",
      "3       3     7.0     NaN  0.016908       NaN\n",
      "4       4     7.0     NaN  0.016908       NaN\n",
      "..    ...     ...     ...       ...       ...\n",
      "139   146     NaN     3.0       NaN  0.016667\n",
      "140   147     NaN     1.0       NaN  0.005556\n",
      "141   148     NaN     1.0       NaN  0.005556\n",
      "142   149     NaN     2.0       NaN  0.011111\n",
      "143   150     NaN     2.0       NaN  0.011111\n",
      "\n",
      "[144 rows x 5 columns]\n",
      "\n",
      "IV for variable ROA : 0.2067238480683407\n",
      "\n",
      "Counts for variable Revenue_Growth_Rate in good data:\n",
      "    Var1  Freq.x\n",
      "0     37      11\n",
      "1     90       8\n",
      "2     60       8\n",
      "3     93       7\n",
      "4     42       7\n",
      "..   ...     ...\n",
      "95    21       1\n",
      "96    15       1\n",
      "97    48       1\n",
      "98    75       1\n",
      "99    56       1\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Counts for variable Revenue_Growth_Rate in bad data:\n",
      "    Var1  Freq.y\n",
      "0     26       5\n",
      "1     55       5\n",
      "2     86       4\n",
      "3     49       4\n",
      "4     68       4\n",
      "..   ...     ...\n",
      "78    29       1\n",
      "79     6       1\n",
      "80    10       1\n",
      "81    98       1\n",
      "82    16       1\n",
      "\n",
      "[83 rows x 2 columns]\n",
      "\n",
      "Merged data:\n",
      "     Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0       0     4.0     3.0  0.009662  0.016667\n",
      "1       1     4.0     3.0  0.009662  0.016667\n",
      "2       2     4.0     3.0  0.009662  0.016667\n",
      "3       3     4.0     NaN  0.009662       NaN\n",
      "4       4     5.0     2.0  0.012077  0.011111\n",
      "..    ...     ...     ...       ...       ...\n",
      "96     96     7.0     1.0  0.016908  0.005556\n",
      "97     97     6.0     1.0  0.014493  0.005556\n",
      "98     98     6.0     1.0  0.014493  0.005556\n",
      "99     99     4.0     3.0  0.009662  0.016667\n",
      "100   100     2.0     1.0  0.004831  0.005556\n",
      "\n",
      "[101 rows x 5 columns]\n",
      "\n",
      "IV for variable Revenue_Growth_Rate : 0.40701496392737907\n",
      "\n",
      "Counts for variable Int_coverage_ratio in good data:\n",
      "     Var1  Freq.x\n",
      "0     -97       6\n",
      "1     -87       6\n",
      "2     -37       6\n",
      "3     -75       5\n",
      "4     -79       5\n",
      "..    ...     ...\n",
      "174    25       1\n",
      "175   -57       1\n",
      "176   -60       1\n",
      "177    44       1\n",
      "178   -33       1\n",
      "\n",
      "[179 rows x 2 columns]\n",
      "\n",
      "Counts for variable Int_coverage_ratio in bad data:\n",
      "     Var1  Freq.y\n",
      "0     -36       6\n",
      "1     -91       5\n",
      "2      92       4\n",
      "3      86       4\n",
      "4     -23       3\n",
      "..    ...     ...\n",
      "116   100       1\n",
      "117    58       1\n",
      "118    82       1\n",
      "119    28       1\n",
      "120    67       1\n",
      "\n",
      "[121 rows x 2 columns]\n",
      "\n",
      "Merged data:\n",
      "     Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0    -100     1.0     2.0  0.002415  0.011111\n",
      "1     -99     3.0     1.0  0.007246  0.005556\n",
      "2     -98     2.0     NaN  0.004831       NaN\n",
      "3     -97     6.0     NaN  0.014493       NaN\n",
      "4     -96     3.0     NaN  0.007246       NaN\n",
      "..    ...     ...     ...       ...       ...\n",
      "187    96     2.0     1.0  0.004831  0.005556\n",
      "188    97     2.0     1.0  0.004831  0.005556\n",
      "189    98     3.0     NaN  0.007246       NaN\n",
      "190    99     2.0     1.0  0.004831  0.005556\n",
      "191   100     3.0     1.0  0.007246  0.005556\n",
      "\n",
      "[192 rows x 5 columns]\n",
      "\n",
      "IV for variable Int_coverage_ratio : 0.5441810083787639\n",
      "\n",
      "Counts for variable Net_Profit_Margin in good data:\n",
      "    Var1  Freq.x\n",
      "0   61.0      12\n",
      "1   18.0      10\n",
      "2   12.0       9\n",
      "3   66.0       9\n",
      "4    3.0       9\n",
      "..   ...     ...\n",
      "91  62.0       1\n",
      "92  49.0       1\n",
      "93  86.0       1\n",
      "94  85.0       1\n",
      "95  16.0       1\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "\n",
      "Counts for variable Net_Profit_Margin in bad data:\n",
      "     Var1  Freq.y\n",
      "0    97.0      10\n",
      "1    92.0      10\n",
      "2    75.0       9\n",
      "3   100.0       8\n",
      "4    99.0       8\n",
      "5    77.0       8\n",
      "6    71.0       8\n",
      "7    89.0       8\n",
      "8    90.0       7\n",
      "9    70.0       7\n",
      "10   76.0       7\n",
      "11   98.0       7\n",
      "12   78.0       7\n",
      "13   96.0       6\n",
      "14   73.0       6\n",
      "15   84.0       6\n",
      "16   93.0       6\n",
      "17   81.0       6\n",
      "18   85.0       6\n",
      "19   74.0       5\n",
      "20   86.0       5\n",
      "21   94.0       5\n",
      "22   82.0       4\n",
      "23   83.0       4\n",
      "24   95.0       4\n",
      "25   91.0       3\n",
      "26   87.0       3\n",
      "27   79.0       3\n",
      "28   72.0       3\n",
      "29   80.0       1\n",
      "\n",
      "Merged data:\n",
      "      Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0    -10.0     3.0     NaN  0.007246       NaN\n",
      "1     -9.0     6.0     NaN  0.014493       NaN\n",
      "2     -8.0     4.0     NaN  0.009662       NaN\n",
      "3     -7.0     4.0     NaN  0.009662       NaN\n",
      "4     -6.0     3.0     NaN  0.007246       NaN\n",
      "..     ...     ...     ...       ...       ...\n",
      "101   96.0     NaN     6.0       NaN  0.033333\n",
      "102   97.0     NaN    10.0       NaN  0.055556\n",
      "103   98.0     NaN     7.0       NaN  0.038889\n",
      "104   99.0     NaN     8.0       NaN  0.044444\n",
      "105  100.0     NaN     8.0       NaN  0.044444\n",
      "\n",
      "[106 rows x 5 columns]\n",
      "\n",
      "IV for variable Net_Profit_Margin : 0.6759821754525905\n",
      "\n",
      "Counts for variable month in good data:\n",
      "    Var1  Freq.x\n",
      "0      1      46\n",
      "1      4      42\n",
      "2      3      40\n",
      "3      7      37\n",
      "4     10      37\n",
      "5     12      34\n",
      "6      8      33\n",
      "7      2      33\n",
      "8      6      31\n",
      "9      5      28\n",
      "10    11      27\n",
      "11     9      26\n",
      "\n",
      "Counts for variable month in bad data:\n",
      "    Var1  Freq.y\n",
      "0      5      21\n",
      "1      1      19\n",
      "2      3      19\n",
      "3      2      18\n",
      "4      4      17\n",
      "5     10      16\n",
      "6     11      15\n",
      "7      6      14\n",
      "8      9      13\n",
      "9      8      12\n",
      "10     7       9\n",
      "11    12       7\n",
      "\n",
      "Merged data:\n",
      "    Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0      1      46      19  0.111111  0.105556\n",
      "1      2      33      18  0.079710  0.100000\n",
      "2      3      40      19  0.096618  0.105556\n",
      "3      4      42      17  0.101449  0.094444\n",
      "4      5      28      21  0.067633  0.116667\n",
      "5      6      31      14  0.074879  0.077778\n",
      "6      7      37       9  0.089372  0.050000\n",
      "7      8      33      12  0.079710  0.066667\n",
      "8      9      26      13  0.062802  0.072222\n",
      "9     10      37      16  0.089372  0.088889\n",
      "10    11      27      15  0.065217  0.083333\n",
      "11    12      34       7  0.082126  0.038889\n",
      "\n",
      "IV for variable month : 0.09630110189720799\n",
      "\n",
      "Counts for variable year_month in good data:\n",
      "       Var1  Freq.x\n",
      "0   2022-10      16\n",
      "1   2020-01      16\n",
      "2   2022-07      16\n",
      "3   2022-04      15\n",
      "4   2020-10      14\n",
      "5   2020-06      14\n",
      "6   2021-04      14\n",
      "7   2021-02      14\n",
      "8   2021-08      13\n",
      "9   2021-01      13\n",
      "10  2021-07      13\n",
      "11  2020-03      12\n",
      "12  2021-12      12\n",
      "13  2021-03      12\n",
      "14  2021-11      12\n",
      "15  2022-12      11\n",
      "16  2021-05      11\n",
      "17  2020-12      11\n",
      "18  2022-11      11\n",
      "19  2020-08      10\n",
      "20  2022-09      10\n",
      "21  2022-08      10\n",
      "22  2022-06      10\n",
      "23  2020-04       9\n",
      "24  2021-09       9\n",
      "25  2023-02       9\n",
      "26  2022-01       9\n",
      "27  2022-02       8\n",
      "28  2023-03       8\n",
      "29  2023-01       8\n",
      "30  2020-07       8\n",
      "31  2022-03       8\n",
      "32  2021-10       7\n",
      "33  2021-06       7\n",
      "34  2020-05       7\n",
      "35  2020-09       7\n",
      "36  2023-05       6\n",
      "37  2022-05       4\n",
      "38  2023-04       4\n",
      "39  2020-11       4\n",
      "40  2020-02       2\n",
      "\n",
      "Counts for variable year_month in bad data:\n",
      "       Var1  Freq.y\n",
      "0   2021-10       9\n",
      "1   2020-02       8\n",
      "2   2020-03       8\n",
      "3   2020-01       7\n",
      "4   2022-05       6\n",
      "5   2020-11       6\n",
      "6   2020-09       6\n",
      "7   2021-08       6\n",
      "8   2020-05       6\n",
      "9   2023-04       5\n",
      "10  2022-06       5\n",
      "11  2022-07       5\n",
      "12  2023-03       5\n",
      "13  2023-05       5\n",
      "14  2021-11       5\n",
      "15  2020-06       5\n",
      "16  2022-04       5\n",
      "17  2020-08       5\n",
      "18  2022-10       4\n",
      "19  2022-03       4\n",
      "20  2021-09       4\n",
      "21  2021-06       4\n",
      "22  2022-01       4\n",
      "23  2023-02       4\n",
      "24  2023-01       4\n",
      "25  2020-04       4\n",
      "26  2021-01       4\n",
      "27  2022-11       4\n",
      "28  2021-05       4\n",
      "29  2021-04       3\n",
      "30  2020-10       3\n",
      "31  2022-12       3\n",
      "32  2022-09       3\n",
      "33  2021-02       3\n",
      "34  2022-02       3\n",
      "35  2020-12       2\n",
      "36  2021-03       2\n",
      "37  2021-12       2\n",
      "38  2020-07       2\n",
      "39  2021-07       2\n",
      "40  2022-08       1\n",
      "\n",
      "Merged data:\n",
      "       Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   2020-01      16       7  0.038647  0.038889\n",
      "1   2020-02       2       8  0.004831  0.044444\n",
      "2   2020-03      12       8  0.028986  0.044444\n",
      "3   2020-04       9       4  0.021739  0.022222\n",
      "4   2020-05       7       6  0.016908  0.033333\n",
      "5   2020-06      14       5  0.033816  0.027778\n",
      "6   2020-07       8       2  0.019324  0.011111\n",
      "7   2020-08      10       5  0.024155  0.027778\n",
      "8   2020-09       7       6  0.016908  0.033333\n",
      "9   2020-10      14       3  0.033816  0.016667\n",
      "10  2020-11       4       6  0.009662  0.033333\n",
      "11  2020-12      11       2  0.026570  0.011111\n",
      "12  2021-01      13       4  0.031401  0.022222\n",
      "13  2021-02      14       3  0.033816  0.016667\n",
      "14  2021-03      12       2  0.028986  0.011111\n",
      "15  2021-04      14       3  0.033816  0.016667\n",
      "16  2021-05      11       4  0.026570  0.022222\n",
      "17  2021-06       7       4  0.016908  0.022222\n",
      "18  2021-07      13       2  0.031401  0.011111\n",
      "19  2021-08      13       6  0.031401  0.033333\n",
      "20  2021-09       9       4  0.021739  0.022222\n",
      "21  2021-10       7       9  0.016908  0.050000\n",
      "22  2021-11      12       5  0.028986  0.027778\n",
      "23  2021-12      12       2  0.028986  0.011111\n",
      "24  2022-01       9       4  0.021739  0.022222\n",
      "25  2022-02       8       3  0.019324  0.016667\n",
      "26  2022-03       8       4  0.019324  0.022222\n",
      "27  2022-04      15       5  0.036232  0.027778\n",
      "28  2022-05       4       6  0.009662  0.033333\n",
      "29  2022-06      10       5  0.024155  0.027778\n",
      "30  2022-07      16       5  0.038647  0.027778\n",
      "31  2022-08      10       1  0.024155  0.005556\n",
      "32  2022-09      10       3  0.024155  0.016667\n",
      "33  2022-10      16       4  0.038647  0.022222\n",
      "34  2022-11      11       4  0.026570  0.022222\n",
      "35  2022-12      11       3  0.026570  0.016667\n",
      "36  2023-01       8       4  0.019324  0.022222\n",
      "37  2023-02       9       4  0.021739  0.022222\n",
      "38  2023-03       8       5  0.019324  0.027778\n",
      "39  2023-04       4       5  0.009662  0.027778\n",
      "40  2023-05       6       5  0.014493  0.027778\n",
      "\n",
      "IV for variable year_month : 0.411398080979177\n",
      "\n",
      "Counts for variable id_capped_0.99 in good data:\n",
      "       Var1  Freq.x\n",
      "0    990.01       4\n",
      "1    456.00       1\n",
      "2     98.00       1\n",
      "3    837.00       1\n",
      "4     83.00       1\n",
      "..      ...     ...\n",
      "406  651.00       1\n",
      "407  568.00       1\n",
      "408  454.00       1\n",
      "409  569.00       1\n",
      "410  343.00       1\n",
      "\n",
      "[411 rows x 2 columns]\n",
      "\n",
      "Counts for variable id_capped_0.99 in bad data:\n",
      "      Var1  Freq.y\n",
      "0    790.0       1\n",
      "1    406.0       1\n",
      "2    558.0       1\n",
      "3    850.0       1\n",
      "4    791.0       1\n",
      "..     ...     ...\n",
      "175  936.0       1\n",
      "176  982.0       1\n",
      "177  365.0       1\n",
      "178  863.0       1\n",
      "179  316.0       1\n",
      "\n",
      "[180 rows x 2 columns]\n",
      "\n",
      "Merged data:\n",
      "       Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0      2.00     NaN     1.0       NaN  0.005556\n",
      "1      3.00     1.0     NaN  0.002415       NaN\n",
      "2      4.00     1.0     NaN  0.002415       NaN\n",
      "3      5.00     NaN     1.0       NaN  0.005556\n",
      "4      8.00     1.0     NaN  0.002415       NaN\n",
      "..      ...     ...     ...       ...       ...\n",
      "586  981.00     NaN     1.0       NaN  0.005556\n",
      "587  982.00     NaN     1.0       NaN  0.005556\n",
      "588  984.00     NaN     1.0       NaN  0.005556\n",
      "589  988.00     1.0     NaN  0.002415       NaN\n",
      "590  990.01     4.0     NaN  0.009662       NaN\n",
      "\n",
      "[591 rows x 5 columns]\n",
      "\n",
      "IV for variable id_capped_0.99 : 0.0\n",
      "\n",
      "Counts for variable boxcox_year in good data:\n",
      "       Var1  Freq.x\n",
      "0  0.018371     414\n",
      "\n",
      "Counts for variable boxcox_year in bad data:\n",
      "       Var1  Freq.y\n",
      "0  0.018371     180\n",
      "\n",
      "Merged data:\n",
      "       Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0  0.018371     414     180       1.0       1.0\n",
      "\n",
      "IV for variable boxcox_year : 0.0\n",
      "\n",
      "Counts for variable business_type_partnership in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     379\n",
      "1   1.0      35\n",
      "\n",
      "Counts for variable business_type_partnership in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     150\n",
      "1   1.0      30\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     379     150  0.915459  0.833333\n",
      "1   1.0      35      30  0.084541  0.166667\n",
      "\n",
      "IV for variable business_type_partnership : 0.06346257937053866\n",
      "\n",
      "Counts for variable business_type_sole_proprietorship in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     345\n",
      "1   1.0      69\n",
      "\n",
      "Counts for variable business_type_sole_proprietorship in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     137\n",
      "1   1.0      43\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     345     137  0.833333  0.761111\n",
      "1   1.0      69      43  0.166667  0.238889\n",
      "\n",
      "IV for variable business_type_sole_proprietorship : 0.032547457388299984\n",
      "\n",
      "Counts for variable credit_history_critical account/ other credits existing (not at this bank) in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     261\n",
      "1   1.0     153\n",
      "\n",
      "Counts for variable credit_history_critical account/ other credits existing (not at this bank) in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     149\n",
      "1   1.0      31\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     261     149  0.630435  0.827778\n",
      "1   1.0     153      31  0.369565  0.172222\n",
      "\n",
      "IV for variable credit_history_critical account/ other credits existing (not at this bank) : 0.20442299393431274\n",
      "\n",
      "Counts for variable credit_history_delay in paying off in the past in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     380\n",
      "1   1.0      34\n",
      "\n",
      "Counts for variable credit_history_delay in paying off in the past in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     163\n",
      "1   1.0      17\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     380     163  0.917874  0.905556\n",
      "1   1.0      34      17  0.082126  0.094444\n",
      "\n",
      "IV for variable credit_history_delay in paying off in the past : 0.0018881563862415216\n",
      "\n",
      "Counts for variable credit_history_existing credits paid back duly till now in good data:\n",
      "   Var1  Freq.x\n",
      "0   1.0     209\n",
      "1   0.0     205\n",
      "\n",
      "Counts for variable credit_history_existing credits paid back duly till now in bad data:\n",
      "   Var1  Freq.y\n",
      "0   1.0      96\n",
      "1   0.0      84\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     205      84  0.495169  0.466667\n",
      "1   1.0     209      96  0.504831  0.533333\n",
      "\n",
      "IV for variable credit_history_existing credits paid back duly till now : 0.0032551787768546176\n",
      "\n",
      "Counts for variable credit_history_no credits taken/ all credits paid back duly in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     405\n",
      "1   1.0       9\n",
      "\n",
      "Counts for variable credit_history_no credits taken/ all credits paid back duly in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     166\n",
      "1   1.0      14\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     405     166  0.978261  0.922222\n",
      "1   1.0       9      14  0.021739  0.077778\n",
      "\n",
      "IV for variable credit_history_no credits taken/ all credits paid back duly : 0.07474053893689278\n",
      "\n",
      "Counts for variable customer_profile_large_enterprises in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     398\n",
      "1   1.0      16\n",
      "\n",
      "Counts for variable customer_profile_large_enterprises in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     169\n",
      "1   1.0      11\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     398     169  0.961353  0.938889\n",
      "1   1.0      16      11  0.038647  0.061111\n",
      "\n",
      "IV for variable customer_profile_large_enterprises : 0.010824387730810552\n",
      "\n",
      "Counts for variable customer_profile_small_businesses in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     372\n",
      "1   1.0      42\n",
      "\n",
      "Counts for variable customer_profile_small_businesses in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     149\n",
      "1   1.0      31\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     372     149  0.898551  0.827778\n",
      "1   1.0      42      31  0.101449  0.172222\n",
      "\n",
      "IV for variable customer_profile_small_businesses : 0.043261034883365544\n",
      "\n",
      "Counts for variable customer_segment_medium_sme in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     314\n",
      "1   1.0     100\n",
      "\n",
      "Counts for variable customer_segment_medium_sme in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     118\n",
      "1   1.0      62\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     314     118  0.758454  0.655556\n",
      "1   1.0     100      62  0.241546  0.344444\n",
      "\n",
      "IV for variable customer_segment_medium_sme : 0.05151848086300119\n",
      "\n",
      "Counts for variable customer_segment_micro_sme in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     325\n",
      "1   1.0      89\n",
      "\n",
      "Counts for variable customer_segment_micro_sme in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0      99\n",
      "1   1.0      81\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     325      99  0.785024      0.55\n",
      "1   1.0      89      81  0.214976      0.45\n",
      "\n",
      "IV for variable customer_segment_micro_sme : 0.2572381951625095\n",
      "\n",
      "Counts for variable customer_segment_small_sme in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     389\n",
      "1   1.0      25\n",
      "\n",
      "Counts for variable customer_segment_small_sme in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     172\n",
      "1   1.0       8\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     389     172  0.939614  0.955556\n",
      "1   1.0      25       8  0.060386  0.044444\n",
      "\n",
      "IV for variable customer_segment_small_sme : 0.0051548457684305595\n",
      "\n",
      "Counts for variable foreign_stakeholders_yes in good data:\n",
      "   Var1  Freq.x\n",
      "0   1.0     396\n",
      "1   0.0      18\n",
      "\n",
      "Counts for variable foreign_stakeholders_yes in bad data:\n",
      "   Var1  Freq.y\n",
      "0   1.0     179\n",
      "1   0.0       1\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0      18       1  0.043478  0.005556\n",
      "1   1.0     396     179  0.956522  0.994444\n",
      "\n",
      "IV for variable foreign_stakeholders_yes : 0.07949901119317462\n",
      "\n",
      "Counts for variable other_debtors_guarantor in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     385\n",
      "1   1.0      29\n",
      "\n",
      "Counts for variable other_debtors_guarantor in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     177\n",
      "1   1.0       3\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     385     177  0.929952  0.983333\n",
      "1   1.0      29       3  0.070048  0.016667\n",
      "\n",
      "IV for variable other_debtors_guarantor : 0.07962352093057354\n",
      "\n",
      "Counts for variable purpose_car (new) in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     326\n",
      "1   1.0      88\n",
      "\n",
      "Counts for variable purpose_car (new) in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     125\n",
      "1   1.0      55\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     326     125   0.78744  0.694444\n",
      "1   1.0      88      55   0.21256  0.305556\n",
      "\n",
      "IV for variable purpose_car (new) : 0.04543558108820977\n",
      "\n",
      "Counts for variable purpose_car (used) in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     356\n",
      "1   1.0      58\n",
      "\n",
      "Counts for variable purpose_car (used) in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     170\n",
      "1   1.0      10\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     356     170  0.859903  0.944444\n",
      "1   1.0      58      10  0.140097  0.055556\n",
      "\n",
      "IV for variable purpose_car (used) : 0.08612414693543763\n",
      "\n",
      "Counts for variable purpose_domestic appliances in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     294\n",
      "1   1.0     120\n",
      "\n",
      "Counts for variable purpose_domestic appliances in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     147\n",
      "1   1.0      33\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     294     147  0.710145  0.816667\n",
      "1   1.0     120      33  0.289855  0.183333\n",
      "\n",
      "IV for variable purpose_domestic appliances : 0.06368263703701174\n",
      "\n",
      "Counts for variable purpose_education in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     406\n",
      "1   1.0       8\n",
      "\n",
      "Counts for variable purpose_education in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     175\n",
      "1   1.0       5\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     406     175  0.980676  0.972222\n",
      "1   1.0       8       5  0.019324  0.027778\n",
      "\n",
      "IV for variable purpose_education : 0.0031412377959267887\n",
      "\n",
      "Counts for variable purpose_furniture/equipment in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     409\n",
      "1   1.0       5\n",
      "\n",
      "Counts for variable purpose_furniture/equipment in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     177\n",
      "1   1.0       3\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     409     177  0.987923  0.983333\n",
      "1   1.0       5       3  0.012077  0.016667\n",
      "\n",
      "IV for variable purpose_furniture/equipment : 0.0014995304817286613\n",
      "\n",
      "Counts for variable purpose_lease_investment in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     399\n",
      "1   1.0      15\n",
      "\n",
      "Counts for variable purpose_lease_investment in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     168\n",
      "1   1.0      12\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     399     168  0.963768  0.933333\n",
      "1   1.0      15      12  0.036232  0.066667\n",
      "\n",
      "IV for variable purpose_lease_investment : 0.01953468349220331\n",
      "\n",
      "Counts for variable purpose_other business spend in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     414\n",
      "\n",
      "Counts for variable purpose_other business spend in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     179\n",
      "1   1.0       1\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0   414.0     179       1.0  0.994444\n",
      "1   1.0     NaN       1       NaN  0.005556\n",
      "\n",
      "IV for variable purpose_other business spend : 3.095025027475228e-05\n",
      "\n",
      "Counts for variable purpose_rent_payment in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     338\n",
      "1   1.0      76\n",
      "\n",
      "Counts for variable purpose_rent_payment in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     141\n",
      "1   1.0      39\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     338     141  0.816425  0.783333\n",
      "1   1.0      76      39  0.183575  0.216667\n",
      "\n",
      "IV for variable purpose_rent_payment : 0.006853782753598721\n",
      "\n",
      "Counts for variable purpose_repairs in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     409\n",
      "1   1.0       5\n",
      "\n",
      "Counts for variable purpose_repairs in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     176\n",
      "1   1.0       4\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     409     176  0.987923  0.977778\n",
      "1   1.0       5       4  0.012077  0.022222\n",
      "\n",
      "IV for variable purpose_repairs : 0.006290743866424756\n",
      "\n",
      "Counts for variable purpose_retraining in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     410\n",
      "1   1.0       4\n",
      "\n",
      "Counts for variable purpose_retraining in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     180\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     410   180.0  0.990338       1.0\n",
      "1   1.0       4     NaN  0.009662       NaN\n",
      "\n",
      "IV for variable purpose_retraining : 9.380496741025103e-05\n",
      "\n",
      "Counts for variable revenue_range_10m+ in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     354\n",
      "1   1.0      60\n",
      "\n",
      "Counts for variable revenue_range_10m+ in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     144\n",
      "1   1.0      36\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     354     144  0.855072       0.8\n",
      "1   1.0      60      36  0.144928       0.2\n",
      "\n",
      "IV for variable revenue_range_10m+ : 0.021404353060996747\n",
      "\n",
      "Counts for variable revenue_range_1m-5m in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     330\n",
      "1   1.0      84\n",
      "\n",
      "Counts for variable revenue_range_1m-5m in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     145\n",
      "1   1.0      35\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     330     145  0.797101  0.805556\n",
      "1   1.0      84      35  0.202899  0.194444\n",
      "\n",
      "IV for variable revenue_range_1m-5m : 0.0004489961077266176\n",
      "\n",
      "Counts for variable revenue_range_5m-10m in good data:\n",
      "   Var1  Freq.x\n",
      "0   1.0     260\n",
      "1   0.0     154\n",
      "\n",
      "Counts for variable revenue_range_5m-10m in bad data:\n",
      "   Var1  Freq.y\n",
      "0   1.0     105\n",
      "1   0.0      75\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     154      75  0.371981  0.416667\n",
      "1   1.0     260     105  0.628019  0.583333\n",
      "\n",
      "IV for variable revenue_range_5m-10m : 0.008367755197204558\n",
      "\n",
      "Counts for variable savings_... < 100 DM in good data:\n",
      "   Var1  Freq.x\n",
      "0   1.0     231\n",
      "1   0.0     183\n",
      "\n",
      "Counts for variable savings_... < 100 DM in bad data:\n",
      "   Var1  Freq.y\n",
      "0   1.0     129\n",
      "1   0.0      51\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     183      51  0.442029  0.283333\n",
      "1   1.0     231     129  0.557971  0.716667\n",
      "\n",
      "IV for variable savings_... < 100 DM : 0.11030224047578063\n",
      "\n",
      "Counts for variable savings_100 <= ... < 500 DM in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     372\n",
      "1   1.0      42\n",
      "\n",
      "Counts for variable savings_100 <= ... < 500 DM in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     158\n",
      "1   1.0      22\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     372     158  0.898551  0.877778\n",
      "1   1.0      42      22  0.101449  0.122222\n",
      "\n",
      "IV for variable savings_100 <= ... < 500 DM : 0.004355498174786698\n",
      "\n",
      "Counts for variable savings_500 <= ... < 1000 DM  in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     385\n",
      "1   1.0      29\n",
      "\n",
      "Counts for variable savings_500 <= ... < 1000 DM  in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     172\n",
      "1   1.0       8\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     385     172  0.929952  0.955556\n",
      "1   1.0      29       8  0.070048  0.044444\n",
      "\n",
      "IV for variable savings_500 <= ... < 1000 DM  : 0.012343762238701584\n",
      "\n",
      "Counts for variable savings_unknown/ no savings account in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     326\n",
      "1   1.0      88\n",
      "\n",
      "Counts for variable savings_unknown/ no savings account in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     164\n",
      "1   1.0      16\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     326     164   0.78744  0.911111\n",
      "1   1.0      88      16   0.21256  0.088889\n",
      "\n",
      "IV for variable savings_unknown/ no savings account : 0.12586260265997798\n",
      "\n",
      "Counts for variable sector_Oil and gas in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     329\n",
      "1   1.0      85\n",
      "\n",
      "Counts for variable sector_Oil and gas in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     138\n",
      "1   1.0      42\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     329     138  0.794686  0.766667\n",
      "1   1.0      85      42  0.205314  0.233333\n",
      "\n",
      "IV for variable sector_Oil and gas : 0.004590193618005171\n",
      "\n",
      "Counts for variable sector_Real Estate in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     277\n",
      "1   1.0     137\n",
      "\n",
      "Counts for variable sector_Real Estate in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     146\n",
      "1   1.0      34\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     277     146  0.669082  0.811111\n",
      "1   1.0     137      34  0.330918  0.188889\n",
      "\n",
      "IV for variable sector_Real Estate : 0.10697758353598588\n",
      "\n",
      "Counts for variable sme_history_begin_... < 1 year  in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     355\n",
      "1   1.0      59\n",
      "\n",
      "Counts for variable sme_history_begin_... < 1 year  in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     142\n",
      "1   1.0      38\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     355     142  0.857488  0.788889\n",
      "1   1.0      59      38  0.142512  0.211111\n",
      "\n",
      "IV for variable sme_history_begin_... < 1 year  : 0.03267642588051434\n",
      "\n",
      "Counts for variable sme_history_begin_1 <= ... < 4 years in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     271\n",
      "1   1.0     143\n",
      "\n",
      "Counts for variable sme_history_begin_1 <= ... < 4 years in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     114\n",
      "1   1.0      66\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     271     114  0.654589  0.633333\n",
      "1   1.0     143      66  0.345411  0.366667\n",
      "\n",
      "IV for variable sme_history_begin_1 <= ... < 4 years : 0.0019710827570414745\n",
      "\n",
      "Counts for variable sme_history_begin_4 <= ... < 7 years in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     339\n",
      "1   1.0      75\n",
      "\n",
      "Counts for variable sme_history_begin_4 <= ... < 7 years in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     160\n",
      "1   1.0      20\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     339     160  0.818841  0.888889\n",
      "1   1.0      75      20  0.181159  0.111111\n",
      "\n",
      "IV for variable sme_history_begin_4 <= ... < 7 years : 0.03999264948607533\n",
      "\n",
      "Counts for variable sme_history_begin_new company in good data:\n",
      "   Var1  Freq.x\n",
      "0   0.0     391\n",
      "1   1.0      23\n",
      "\n",
      "Counts for variable sme_history_begin_new company in bad data:\n",
      "   Var1  Freq.y\n",
      "0   0.0     163\n",
      "1   1.0      17\n",
      "\n",
      "Merged data:\n",
      "   Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.0     391     163  0.944444  0.905556\n",
      "1   1.0      23      17  0.055556  0.094444\n",
      "\n",
      "IV for variable sme_history_begin_new company : 0.02227075228410938\n",
      "\n",
      "Counts for variable business_type_mean_encoded in good data:\n",
      "       Var1  Freq.x\n",
      "0  0.260870     310\n",
      "1  0.391061      69\n",
      "2  0.407407      35\n",
      "\n",
      "Counts for variable business_type_mean_encoded in bad data:\n",
      "       Var1  Freq.y\n",
      "0  0.260870     107\n",
      "1  0.391061      43\n",
      "2  0.407407      30\n",
      "\n",
      "Merged data:\n",
      "       Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0  0.260870     310     107  0.748792  0.594444\n",
      "1  0.391061      69      43  0.166667  0.238889\n",
      "2  0.407407      35      30  0.084541  0.166667\n",
      "\n",
      "IV for variable business_type_mean_encoded : 0.11737242305424454\n",
      "\n",
      "Counts for variable other_debtors_mean_encoded in good data:\n",
      "       Var1  Freq.x\n",
      "0  0.299890     372\n",
      "1  0.192308      29\n",
      "2  0.439024      13\n",
      "\n",
      "Counts for variable other_debtors_mean_encoded in bad data:\n",
      "       Var1  Freq.y\n",
      "0  0.299890     169\n",
      "1  0.439024       8\n",
      "2  0.192308       3\n",
      "\n",
      "Merged data:\n",
      "       Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0  0.192308      29       3  0.070048  0.016667\n",
      "1  0.299890     372     169  0.898551  0.938889\n",
      "2  0.439024      13       8  0.031401  0.044444\n",
      "\n",
      "IV for variable other_debtors_mean_encoded : 0.08294672761055182\n",
      "\n",
      "Counts for variable purpose_mean_encoded in good data:\n",
      "       Var1  Freq.x\n",
      "0  0.221429     120\n",
      "1  0.380342      88\n",
      "2  0.320442      76\n",
      "3  0.165049      58\n",
      "4  0.347826      35\n",
      "5  0.440000      15\n",
      "6  0.363636       8\n",
      "7  0.333333       5\n",
      "8  0.416667       5\n",
      "9  0.111111       4\n",
      "\n",
      "Counts for variable purpose_mean_encoded in bad data:\n",
      "       Var1  Freq.y\n",
      "0  0.380342      55\n",
      "1  0.320442      39\n",
      "2  0.221429      33\n",
      "3  0.347826      18\n",
      "4  0.440000      12\n",
      "5  0.165049      10\n",
      "6  0.363636       5\n",
      "7  0.333333       4\n",
      "8  0.416667       3\n",
      "9  0.400000       1\n",
      "\n",
      "Merged data:\n",
      "        Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0   0.111111     4.0     NaN  0.009662       NaN\n",
      "1   0.165049    58.0    10.0  0.140097  0.055556\n",
      "2   0.221429   120.0    33.0  0.289855  0.183333\n",
      "3   0.320442    76.0    39.0  0.183575  0.216667\n",
      "4   0.333333     5.0     4.0  0.012077  0.022222\n",
      "5   0.347826    35.0    18.0  0.084541  0.100000\n",
      "6   0.363636     8.0     5.0  0.019324  0.027778\n",
      "7   0.380342    88.0    55.0  0.212560  0.305556\n",
      "8   0.400000     NaN     1.0       NaN  0.005556\n",
      "9   0.416667     5.0     3.0  0.012077  0.016667\n",
      "10  0.440000    15.0    12.0  0.036232  0.066667\n",
      "\n",
      "IV for variable purpose_mean_encoded : 0.1981104871759441\n",
      "\n",
      "Counts for variable sector_risk_capped_0.99_woe_encoded in good data:\n",
      "       Var1  Freq.x\n",
      "0 -0.001891     414\n",
      "\n",
      "Counts for variable sector_risk_capped_0.99_woe_encoded in bad data:\n",
      "       Var1  Freq.y\n",
      "0 -0.001891     180\n",
      "\n",
      "Merged data:\n",
      "       Var1  Freq.x  Freq.y  percentx  percenty\n",
      "0 -0.001891     414     180       1.0       1.0\n",
      "\n",
      "IV for variable sector_risk_capped_0.99_woe_encoded : 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>date</td>\n",
       "      <td>0.131081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saving_ratio</td>\n",
       "      <td>0.488495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max_dpd_6_months</td>\n",
       "      <td>0.014473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>sme_history_begin_new company</td>\n",
       "      <td>0.022271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>business_type_mean_encoded</td>\n",
       "      <td>0.117372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>other_debtors_mean_encoded</td>\n",
       "      <td>0.082947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>purpose_mean_encoded</td>\n",
       "      <td>0.198110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>sector_risk_capped_0.99_woe_encoded</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Variable        IV\n",
       "0                            Unnamed: 0  0.000000\n",
       "1                                    id  0.000000\n",
       "2                                  date  0.131081\n",
       "3                          saving_ratio  0.488495\n",
       "4                      max_dpd_6_months  0.014473\n",
       "..                                  ...       ...\n",
       "59        sme_history_begin_new company  0.022271\n",
       "60           business_type_mean_encoded  0.117372\n",
       "61           other_debtors_mean_encoded  0.082947\n",
       "62                 purpose_mean_encoded  0.198110\n",
       "63  sector_risk_capped_0.99_woe_encoded  0.000000\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the function for each of the features except default_flag and appending the variables in one columns and there information values in second columns of a summary dataframe.\n",
    "# This user defined function is created beecause we have to repeatedly use the function of the training, test and validation data.\n",
    "def IV_calc_data(data, default_flag): \n",
    "    iv_column_names = [] #Initializes lists to store variable names (iv_column_names) and their corresponding IVs (Information_Values)\n",
    "    Information_Values = [] \n",
    "\n",
    "    # Computes the Information Value (IV) for each variable in the dataset except the default_flag variable\n",
    "    for column in data.columns: \n",
    "        if column != default_flag: # Iterates through each column in data (excluding default_flag).\n",
    "            iv = IV_calc(data, default_flag, column)# Calls IV_calc function to compute IV for each variable.\n",
    "            iv_column_names.append(column)           \n",
    "            Information_Values.append(iv)            # Appends variable names and their IVs to respective lists\n",
    "    \n",
    "    \n",
    "    iv_summary = pd.DataFrame({'Variable': iv_column_names, 'IV': Information_Values}) # Constructs a DataFrame (iv_summary) containing variables and their calculated IVs.\n",
    "    iv_summary = iv_summary[iv_summary['Variable'] != default_flag].reset_index(drop=True)# Filters out the default_flag variable from the summary.\n",
    "\n",
    "    return iv_summary # Returns a DataFrame (iv_summary) with variables and their corresponding IVs.\n",
    "\n",
    "iv_results = IV_calc_data(train_data_corr_eliminated,\"default_flag\")\n",
    "iv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27cacf42-b0c5-407e-b693-f6c8321e89b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable    year_month\n",
       "IV            0.675982\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sector_risk_mean_encoded  and sector_risk_woe_encoded have 0 IV \n",
    "iv_results.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3dd9c83-4c95-4712-a299-80ec6f6e5a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable    EBITDA\n",
       "IV             0.0\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_results.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33209a91-334c-46f6-b730-e93362da8f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Net_Profit_Margin</td>\n",
       "      <td>0.675982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Int_coverage_ratio</td>\n",
       "      <td>0.544181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saving_ratio</td>\n",
       "      <td>0.488495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>year_month</td>\n",
       "      <td>0.411398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Revenue_Growth_Rate</td>\n",
       "      <td>0.407015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>boxcox_year</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>id_capped_0.99</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>sector_risk_capped_0.99_woe_encoded</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Variable        IV\n",
       "19                    Net_Profit_Margin  0.675982\n",
       "18                   Int_coverage_ratio  0.544181\n",
       "3                          saving_ratio  0.488495\n",
       "21                           year_month  0.411398\n",
       "17                  Revenue_Growth_Rate  0.407015\n",
       "..                                  ...       ...\n",
       "0                            Unnamed: 0  0.000000\n",
       "1                                    id  0.000000\n",
       "23                          boxcox_year  0.000000\n",
       "22                       id_capped_0.99  0.000000\n",
       "63  sector_risk_capped_0.99_woe_encoded  0.000000\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_results_sorted = iv_results.sort_values(by='IV', ascending=False)\n",
    "iv_results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb8c7c32-f3d5-4eda-9da2-3b96def17888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Net_Profit_Margin</td>\n",
       "      <td>0.675982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Int_coverage_ratio</td>\n",
       "      <td>0.544181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saving_ratio</td>\n",
       "      <td>0.488495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>year_month</td>\n",
       "      <td>0.411398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Revenue_Growth_Rate</td>\n",
       "      <td>0.407015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average_credit_duration</td>\n",
       "      <td>0.343678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ROE</td>\n",
       "      <td>0.336657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>duration_in_month</td>\n",
       "      <td>0.285615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>customer_segment_micro_sme</td>\n",
       "      <td>0.257238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ROA</td>\n",
       "      <td>0.206724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EBITDA</td>\n",
       "      <td>0.204461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>credit_history_critical account/ other credits...</td>\n",
       "      <td>0.204423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Variable        IV\n",
       "19                                  Net_Profit_Margin  0.675982\n",
       "18                                 Int_coverage_ratio  0.544181\n",
       "3                                        saving_ratio  0.488495\n",
       "21                                         year_month  0.411398\n",
       "17                                Revenue_Growth_Rate  0.407015\n",
       "10                            average_credit_duration  0.343678\n",
       "15                                                ROE  0.336657\n",
       "6                                   duration_in_month  0.285615\n",
       "33                         customer_segment_micro_sme  0.257238\n",
       "16                                                ROA  0.206724\n",
       "14                                             EBITDA  0.204461\n",
       "26  credit_history_critical account/ other credits...  0.204423"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_iv_results =iv_results_sorted[iv_results_sorted['IV'] > 0.2]\n",
    "filtered_iv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f607d-a30e-46be-84b3-0fb74c5173ba",
   "metadata": {},
   "source": [
    "# Univariate GINI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e9a7f5-bf27-4703-a8ee-838e7fc86afe",
   "metadata": {},
   "source": [
    "The Gini coefficient measures the inequality among values of a frequency distribution. In the context of predictive modeling:\n",
    "\n",
    "The Gini coefficient ranges from -1 to 1= (2* AUROC)-1\n",
    "\n",
    "1 indicates perfect predictive power (all predicted probabilities are either 0 or 1).\n",
    "0 indicates no predictive power (model performance is equivalent to random guessing).\n",
    "Negative values suggest worse than random predictions.\n",
    "Gini coefficients help in identifying variables that are most predictive of the outcome variable (default_flag in this case), making it a valuable tool for feature selection and model evaluation in credit scoring and risk assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bedf423-6b24-4950-b7e5-85aae8af3911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1144d8-bcc7-4844-9ba7-223b3d73a8ad",
   "metadata": {},
   "source": [
    "Calculate the Gini coefficient from the estimated values calculated by logistic regression for each variable in the dataset.\n",
    "\n",
    "Parameters:\n",
    "- data (DataFrame): The dataset.\n",
    "- default_flag (str): The name of the default flag variable.\n",
    "\n",
    "Returns:\n",
    "DataFrame: DataFrame containing variables and their corresponding Gini values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab495d8c-b11d-43aa-b180-f6d78c0323e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini_univariate_data(data, default_flag): # User Defined Function to calculate the GINI values\n",
    "    gini_values = []\n",
    "    variable_names = []\n",
    "\n",
    "    for column in data.columns:\n",
    "        if column != default_flag:\n",
    "            X = data[[column]]\n",
    "            y = data[default_flag]\n",
    "\n",
    "            # Fit logistic regression model\n",
    "            model = LogisticRegression(solver='liblinear')\n",
    "            model.fit(X, y)\n",
    "\n",
    "            # Predict probabilities for the default or bad cases\n",
    "            y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "            # Calculate Gini coefficient\n",
    "            gini_value = 2 * roc_auc_score(y, y_pred) - 1\n",
    "\n",
    "            # Append variable name and Gini value to lists\n",
    "            variable_names.append(column)\n",
    "            gini_values.append(gini_value)\n",
    "\n",
    "    # Create DataFrame from lists\n",
    "    gini_df = pd.DataFrame({'Variable': variable_names, 'Gini': gini_values})\n",
    "\n",
    "    # Sort DataFrame by Gini values in descending order\n",
    "    ordered_gini_df = gini_df.sort_values(by='Gini', ascending=False)\n",
    "\n",
    "    # Reset index\n",
    "    ordered_gini_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return ordered_gini_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12bac01a-bd1f-4644-ad17-9ead6e38f061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Net_Profit_Margin</td>\n",
       "      <td>0.870867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROA</td>\n",
       "      <td>0.716787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sector_risk</td>\n",
       "      <td>0.637024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROE</td>\n",
       "      <td>0.524007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saving_ratio</td>\n",
       "      <td>0.496444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Variable      Gini\n",
       "0  Net_Profit_Margin  0.870867\n",
       "1                ROA  0.716787\n",
       "2        sector_risk  0.637024\n",
       "3                ROE  0.524007\n",
       "4       saving_ratio  0.496444"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'date',\"year_month\"  column and calculate Gini coefficient over the training data\n",
    "\n",
    "gini_result = Gini_univariate_data(train_data_corr_eliminated.drop([\"date\",\"year_month\"],axis =1), \"default_flag\")\n",
    "filtered_gini_result = gini_result[gini_result['Gini'] > 0.3]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "filtered_gini_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcdccb5-9dea-4aa0-9ced-6f8013885b14",
   "metadata": {},
   "source": [
    "Netprofit margin implies highest GINI  coefficient and hence string discrimnatory power follower by ROA and Sector_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ed2c2-dd5f-4254-b035-354131e4dbba",
   "metadata": {},
   "source": [
    "# COX Proportionate Hazard model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f8951-a9ba-4c5f-9bf7-39e8db29a0d7",
   "metadata": {},
   "source": [
    "The Cox Proportional Hazards Model, often just called the Cox model, is a statistical technique used in survival analysis. It helps us understand how different factors affect the time it takes for an event to happen. The “event” could be anything: death, equipment failure, customer churn,loan default etc.\n",
    "Survival analysis is used to study time-to-event data. For example:\n",
    "\n",
    "How long does a patient survive after treatment?\n",
    "How many months does a customer stay subscribed before leaving?\n",
    "How long until a machine breaks down?\n",
    "In this context:\n",
    "\n",
    "Survival time means the time until the event occurs\n",
    "\n",
    "Censoring happens when we don't see the event before the end of the study (e.g., the customer hasn’t left yet).\n",
    "\n",
    "the Cox model answers this key question:\n",
    "\n",
    "How does each variable (like age, gender, income, etc.) affect the risk of the event happening at any point in time?\n",
    "\n",
    "survival_function is derived from the baseline hazard function computed using the model parameters and feature values.\n",
    "PD = 1- Survival_function\n",
    "PD lies in the range[0,1] facilitates interpretation and comparison across different predictions.\n",
    "\n",
    "BASELINE HAZARD FUNCTION =h(t∣X)=h0(T).e^B1X1+B2X2+B3X3+......+BnXn\n",
    "If B is the coefficents of the covariates X,b>0 increases hazarard risk,b<0 decreases hazard risk\n",
    "e^B>1 Higher Risk\n",
    "e^B=1 No effect\n",
    "e^B<1 Lower Risk\n",
    "\n",
    "Key Concepts:\n",
    "\n",
    "Survival Analysis: Analytical techniques used to predict the time until an event of interest occurs.\n",
    "\n",
    "Hazard Function: Instantaneous rate of occurrence of an event at a given time, conditioned on survival up to that time.\n",
    "\n",
    "Proportional Hazards Assumption: Assumes that the hazard ratio between any two individuals is constant over time, given their covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1541a330-1485-401f-b631-dd8b8294c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lifelines import CoxPHFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4cbe3c3d-7499-4096-a0be-222c52cf9a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariate\n",
      "Net_Profit_Margin    0.041587\n",
      "ROA                  0.010448\n",
      "sector_risk          0.168348\n",
      "ROE                  0.006087\n",
      "saving_ratio         0.214596\n",
      "Name: coef, dtype: float64\n",
      "      baseline hazard\n",
      "0.0          0.000809\n",
      "1.0          0.001225\n",
      "2.0          0.001257\n",
      "3.0          0.002590\n",
      "4.0          0.003519\n",
      "5.0          0.002792\n",
      "6.0          0.001936\n",
      "7.0          0.002471\n",
      "8.0          0.002537\n",
      "9.0          0.002092\n",
      "10.0         0.002702\n",
      "11.0         0.003919\n",
      "12.0         0.001213\n",
      "13.0         0.003097\n",
      "14.0         0.005826\n",
      "15.0         0.002099\n",
      "16.0         0.003632\n",
      "17.0         0.003097\n",
      "18.0         0.003186\n",
      "19.0         0.001708\n",
      "20.0         0.000870\n",
      "21.0         0.003545\n",
      "22.0         0.003687\n",
      "23.0         0.005856\n",
      "24.0         0.004165\n",
      "25.0         0.004439\n",
      "26.0         0.003682\n",
      "27.0         0.007823\n",
      "28.0         0.007313\n",
      "29.0         0.008078\n",
      "30.0         0.009348\n",
      "31.0         0.016391\n",
      "32.0         0.013671\n",
      "33.0         0.009633\n",
      "34.0         0.007256\n",
      "35.0         0.008092\n",
      "36.0         0.018150\n",
      "37.0         0.022649\n",
      "38.0         0.023227\n",
      "39.0         0.043834\n",
      "40.0         0.112250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\AppData\\Local\\Temp\\ipykernel_9964\\1796055509.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data_corr_eliminated[['date','year_month']] = test_data[['date','year_month']]\n",
      "C:\\Users\\siddh\\AppData\\Local\\Temp\\ipykernel_9964\\1796055509.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_data_corr_eliminated[['date','year_month']] = validation_data[['date','year_month']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>saving_ratio</th>\n",
       "      <th>default_flag</th>\n",
       "      <th>max_dpd_6_months</th>\n",
       "      <th>problematic_cheque_count</th>\n",
       "      <th>duration_in_month</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>installment_as_income_perc</th>\n",
       "      <th>...</th>\n",
       "      <th>sector_Real Estate</th>\n",
       "      <th>sme_history_begin_... &lt; 1 year</th>\n",
       "      <th>sme_history_begin_1 &lt;= ... &lt; 4 years</th>\n",
       "      <th>sme_history_begin_4 &lt;= ... &lt; 7 years</th>\n",
       "      <th>sme_history_begin_new company</th>\n",
       "      <th>business_type_mean_encoded</th>\n",
       "      <th>other_debtors_mean_encoded</th>\n",
       "      <th>purpose_mean_encoded</th>\n",
       "      <th>sector_risk_capped_0.99_woe_encoded</th>\n",
       "      <th>PD_cph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>828</td>\n",
       "      <td>829</td>\n",
       "      <td>2020-06-27</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>8335</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.29989</td>\n",
       "      <td>0.165049</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.988274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>321</td>\n",
       "      <td>322</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1938</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.29989</td>\n",
       "      <td>0.221429</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.986574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>493</td>\n",
       "      <td>494</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>368</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.29989</td>\n",
       "      <td>0.221429</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.209869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>836</td>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1082</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.29989</td>\n",
       "      <td>0.380342</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.868957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>923</td>\n",
       "      <td>924</td>\n",
       "      <td>2022-01-30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.29989</td>\n",
       "      <td>0.380342</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.024947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   id       date  saving_ratio  default_flag  max_dpd_6_months  \\\n",
       "828         828  829 2020-06-27          0.15             1                 0   \n",
       "321         321  322 2022-02-10          0.64             1                 0   \n",
       "493         493  494 2020-08-06          0.49             0                 0   \n",
       "835         835  836 2023-02-16          0.67             1                 0   \n",
       "923         923  924 2022-01-30          0.46             0                 0   \n",
       "\n",
       "     problematic_cheque_count  duration_in_month  credit_amount  \\\n",
       "828                         0                 36           8335   \n",
       "321                         1                 24           1938   \n",
       "493                         3                  6            368   \n",
       "835                         2                 12           1082   \n",
       "923                         2                 12           2002   \n",
       "\n",
       "     installment_as_income_perc  ...  sector_Real Estate  \\\n",
       "828                           3  ...                 0.0   \n",
       "321                           4  ...                 0.0   \n",
       "493                           4  ...                 0.0   \n",
       "835                           4  ...                 0.0   \n",
       "923                           3  ...                 0.0   \n",
       "\n",
       "     sme_history_begin_... < 1 year   sme_history_begin_1 <= ... < 4 years  \\\n",
       "828                              0.0                                   0.0   \n",
       "321                              1.0                                   0.0   \n",
       "493                              0.0                                   0.0   \n",
       "835                              0.0                                   1.0   \n",
       "923                              0.0                                   0.0   \n",
       "\n",
       "     sme_history_begin_4 <= ... < 7 years  sme_history_begin_new company  \\\n",
       "828                                   0.0                            0.0   \n",
       "321                                   0.0                            0.0   \n",
       "493                                   0.0                            0.0   \n",
       "835                                   0.0                            0.0   \n",
       "923                                   1.0                            0.0   \n",
       "\n",
       "     business_type_mean_encoded  other_debtors_mean_encoded  \\\n",
       "828                    0.407407                     0.29989   \n",
       "321                    0.260870                     0.29989   \n",
       "493                    0.260870                     0.29989   \n",
       "835                    0.260870                     0.29989   \n",
       "923                    0.391061                     0.29989   \n",
       "\n",
       "     purpose_mean_encoded  sector_risk_capped_0.99_woe_encoded    PD_cph  \n",
       "828              0.165049                            -0.001891  0.988274  \n",
       "321              0.221429                            -0.001891  0.986574  \n",
       "493              0.221429                            -0.001891  0.209869  \n",
       "835              0.380342                            -0.001891  0.868957  \n",
       "923              0.380342                            -0.001891  0.024947  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "def prepare_data(data, duration_col, event_col, features):\n",
    "    \"\"\"\n",
    "    Prepare the dataset for survival analysis.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Create a new numeric year_month column\n",
    "    unique_year_months = data[duration_col].unique()\n",
    "    year_month_map = {month: i for i, month in enumerate(unique_year_months)}\n",
    "    \n",
    "    data['year_month'] = data[duration_col].map(year_month_map)\n",
    "    \n",
    "    data[event_col] = data[event_col].astype(int)\n",
    "    \n",
    "    data = data[features + ['year_month', event_col]]\n",
    "    return data\n",
    "\n",
    "def train_survival_model(train_data, features, duration_col='year_month', event_col='default_flag'):\n",
    "    \"\"\"\n",
    "    Train the Cox Proportional Hazards model on the training data.\n",
    "    \"\"\"\n",
    "    train_data_prepared = prepare_data(train_data, duration_col, event_col, features)\n",
    "    \n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(train_data_prepared, duration_col=duration_col, event_col=event_col)\n",
    "    \n",
    "    return cph\n",
    "\n",
    "def predict_pd(model, data, features, duration_col='year_month', event_col='default_flag'):\n",
    "    \"\"\"\n",
    "    Predict the probability of default (PD) using the trained survival model.\n",
    "    \"\"\"\n",
    "    data_prepared = prepare_data(data, duration_col, event_col, features)\n",
    "    \n",
    "    # Predict the survival function\n",
    "    survival_function = model.predict_survival_function(data_prepared).T\n",
    "    \n",
    "    # Calculate the probability of default (PD) as 1 - survival probability at the last time point\n",
    "    pd_values = 1 - survival_function.iloc[:, -1]\n",
    "    \n",
    "    # Scale PD values to [0, 1\n",
    "    pd_values_scaled = (pd_values - pd_values.min()) / (pd_values.max() - pd_values.min())\n",
    "    \n",
    "    data['PD_cph'] = pd_values_scaled.values\n",
    "    return data\n",
    "\n",
    "def get_model_coefficients(model):\n",
    "    \"\"\"\n",
    "    Get the coefficients and intercept from the Cox Proportional Hazards model.\n",
    "    \"\"\"\n",
    "    coefficients = model.params_\n",
    "    intercept = model.baseline_hazard_\n",
    "    \n",
    "    return coefficients, intercept\n",
    "\n",
    "\n",
    "# Adding date and period information to data\n",
    "train_data_corr_eliminated[['date','year_month']] = train_data[['date','year_month']]\n",
    "test_data_corr_eliminated[['date','year_month']] = test_data[['date','year_month']]\n",
    "validation_data_corr_eliminated[['date','year_month']] = validation_data[['date','year_month']]\n",
    "\n",
    "train_data_survival = train_data_corr_eliminated.copy()\n",
    "test_data_survival = test_data_corr_eliminated.copy()\n",
    "validation_data_survival = validation_data_corr_eliminated.copy()\n",
    "\n",
    "# Feature selection based on gini output\n",
    "features = [\"Net_Profit_Margin\",\"ROA\",\"sector_risk\",\"ROE\",\"saving_ratio\"]\n",
    "\n",
    "# Train the survival model on train_data\n",
    "cph_model = train_survival_model(train_data_survival, features)\n",
    "\n",
    "# Predict PD on train_data, test_data, and validation_data\n",
    "train_data_with_pd = predict_pd(cph_model, train_data_survival, features)\n",
    "test_data_with_pd = predict_pd(cph_model, test_data_survival, features)\n",
    "validation_data_with_pd = predict_pd(cph_model, validation_data_survival, features)\n",
    "\n",
    "coefficients, intercept = get_model_coefficients(cph_model)\n",
    "print(coefficients)\n",
    "print(intercept)\n",
    "# Display the resulting datasets with PD values\n",
    "# print(train_data_with_pd.head())\n",
    "test_data_with_pd.head()\n",
    "# test_data_with_pd.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b613de-bab8-49c6-a253-c2cf2d398c22",
   "metadata": {},
   "source": [
    "# Applying Logistic Regression to Predict PD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e2159-5661-46d7-bc56-98c839db6e36",
   "metadata": {},
   "source": [
    "Input Parameters\n",
    "1-Data\n",
    "2_Features\n",
    "3_Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d932d614-9586-4feb-bd76-23fe356e2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the specified features and the target variable based on the Uni Variate GINI on the enture dataset\n",
    "features = [\"Net_Profit_Margin\",\"ROA\",\"sector_risk\",\"ROE\",\"saving_ratio\"]\n",
    "X = data[features]\n",
    "y = data[\"default_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8755fbc4-748f-469a-836e-2351422c0719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1410cbd-dae2-40a4-a664-8c05da9ae69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_logistic = train_data_corr_eliminated.copy()\n",
    "test_data_logistic = test_data_corr_eliminated.copy()\n",
    "validation_data_logistic = validation_data_corr_eliminated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a783571-33b9-4be0-b640-748630c20d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data_logistic[features]\n",
    "y = train_data_logistic[\"default_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9080352-355b-46f1-ad01-4e083dc2baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train=model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77660a7b-8956-4694-acb5-a167609148d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_logistic['PD_logistic'] = model.predict_proba(train_data_logistic[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41b4acf7-750c-4967-8066-1002b9350b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients and intercept\n",
    "coef = model_train.coef_[0]\n",
    "intercept = model_train.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "098e11be-6958-4689-a172-7b8b9190fe25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variables</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Net_Profit_Margin</td>\n",
       "      <td>0.124691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROA</td>\n",
       "      <td>0.049760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sector_risk</td>\n",
       "      <td>0.544675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROE</td>\n",
       "      <td>0.029576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saving_ratio</td>\n",
       "      <td>1.902616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-18.754691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Variables  Coefficients\n",
       "0  Net_Profit_Margin      0.124691\n",
       "1                ROA      0.049760\n",
       "2        sector_risk      0.544675\n",
       "3                ROE      0.029576\n",
       "4       saving_ratio      1.902616\n",
       "5          Intercept    -18.754691"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame for coefficients and intercept\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Variables': features + ['Intercept'],\n",
    "    'Coefficients': np.append(coef, intercept)\n",
    "})\n",
    "coefficients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "411e7df1-58c0-457f-a3a6-252967338b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_data_logistic[features]\n",
    "y = test_data_logistic[\"default_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52592af8-7c19-4e17-95db-8bde83c8c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test=model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a22cd466-557f-4e05-972a-dc5de1c3c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_logistic['PD_logistic'] = model.predict_proba(test_data_logistic[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bede35e-ace6-49b7-949b-a2cfb6a41140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients and intercept\n",
    "coef = model_test.coef_[0]\n",
    "intercept = model_test.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84411619-98ea-46f5-93c8-14d4cac514a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variables</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Net_Profit_Margin</td>\n",
       "      <td>0.149666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROA</td>\n",
       "      <td>0.069558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sector_risk</td>\n",
       "      <td>0.631891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROE</td>\n",
       "      <td>0.028253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saving_ratio</td>\n",
       "      <td>1.313105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-22.838333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Variables  Coefficients\n",
       "0  Net_Profit_Margin      0.149666\n",
       "1                ROA      0.069558\n",
       "2        sector_risk      0.631891\n",
       "3                ROE      0.028253\n",
       "4       saving_ratio      1.313105\n",
       "5          Intercept    -22.838333"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame for coefficients and intercept\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Variables': features + ['Intercept'],\n",
    "    'Coefficients': np.append(coef, intercept)\n",
    "})\n",
    "coefficients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5db58da-4509-486a-8f90-f3a7d4e079cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = validation_data_logistic[features]\n",
    "y = validation_data_logistic[\"default_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c4bc7be-edc2-4b93-a61f-9f8e8543b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_valid=model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a969c85-bc60-428c-84fd-c3166d2b2fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=validation_data_logistic[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "103ede4b-3819-44ca-a2c0-1a054893f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_logistic['PD'] = model.predict(validation_data_logistic[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72dc93d7-785d-413b-90d3-4a9fd09da977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22     0\n",
       "26     0\n",
       "32     0\n",
       "46     0\n",
       "58     0\n",
       "      ..\n",
       "989    0\n",
       "991    0\n",
       "995    0\n",
       "997    0\n",
       "998    1\n",
       "Name: PD, Length: 151, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data_logistic['PD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7443c135-763c-4c2f-ba53-f2d74ae9bb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22     4.369834e-09\n",
       "26     4.102796e-08\n",
       "32     2.579425e-05\n",
       "46     2.357610e-05\n",
       "58     3.231834e-09\n",
       "           ...     \n",
       "989    3.003442e-04\n",
       "991    3.520982e-03\n",
       "995    6.096819e-08\n",
       "997    1.880723e-02\n",
       "998    7.926656e-01\n",
       "Name: PD_logistic, Length: 151, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data_logistic['PD_logistic'] = model.predict_proba(validation_data_logistic[features])[:, 1]\n",
    "validation_data_logistic['PD_logistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f94aa16-633f-4e3e-9222-f5d7690559b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients and intercept\n",
    "coef = model_valid.coef_[0]\n",
    "intercept = model_valid.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6cb92ad7-01c4-470b-8f62-abc6eb33a84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients & Intercepts DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variables</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Net_Profit_Margin</td>\n",
       "      <td>0.143053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROA</td>\n",
       "      <td>0.077935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sector_risk</td>\n",
       "      <td>0.927443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROE</td>\n",
       "      <td>0.015274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saving_ratio</td>\n",
       "      <td>1.289052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-23.503604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Variables  Coefficients\n",
       "0  Net_Profit_Margin      0.143053\n",
       "1                ROA      0.077935\n",
       "2        sector_risk      0.927443\n",
       "3                ROE      0.015274\n",
       "4       saving_ratio      1.289052\n",
       "5          Intercept    -23.503604"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame for coefficients and intercept\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Variables': features + ['Intercept'],\n",
    "    'Coefficients': np.append(coef, intercept)\n",
    "})\n",
    "print(f\"Coefficients & Intercepts DataFrame\")\n",
    "coefficients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "534217c5-5efe-4ab2-becc-50a71205c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Test and Validation data have the different coefficients and Intercepts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c336ef5-e42f-4d58-bbfa-ab83b2002133",
   "metadata": {},
   "source": [
    "# classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6221c-c47b-4828-90f4-a4abd486a419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3c55936-6fdc-4c58-b7da-e2c35426548b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.968610</td>\n",
       "      <td>111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.953642</td>\n",
       "      <td>0.953642</td>\n",
       "      <td>0.953642</td>\n",
       "      <td>0.953642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.943681</td>\n",
       "      <td>0.936486</td>\n",
       "      <td>0.940001</td>\n",
       "      <td>151.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.953369</td>\n",
       "      <td>0.953642</td>\n",
       "      <td>0.953453</td>\n",
       "      <td>151.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.964286  0.972973  0.968610  111.000000\n",
       "1              0.923077  0.900000  0.911392   40.000000\n",
       "accuracy       0.953642  0.953642  0.953642    0.953642\n",
       "macro avg      0.943681  0.936486  0.940001  151.000000\n",
       "weighted avg   0.953369  0.953642  0.953453  151.000000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_dict=classification_report(y, validation_data_logistic['PD'],output_dict=True)\n",
    "df_Classification_report = pd.DataFrame(report_dict).transpose()\n",
    "df_Classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde723fd-9612-403c-9d6c-023a4f37dd84",
   "metadata": {},
   "source": [
    "Permutation Feature Importance\n",
    "Permutation Feature Importance (PFI) is a model-agnostic technique to measure a feature's importance by shuffling its values and observing the resulting drop in model performance (score/accuracy), indicating how much the model relied on that feature for accurate predictions. If shuffling a feature significantly worsens the model's score, that feature is important; if the score barely changes, the feature is less crucial. It's great for black-box models but can struggle with highly correlated features, potentially underestimating their individual importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1dab1-7ec3-4aff-9420-93b37e93ab6e",
   "metadata": {},
   "source": [
    "    -Calculate the Baseline Score: for RandomForestClassifier model\n",
    "    -Evaluate the model on the testing set (X_test and y_test) using the specified metric to get the baseline score.\n",
    "    -Initialize an Array to Store Importances:\n",
    "    -Create an array of zeros with the same length as the number of features to store the importance values.\n",
    "    -Permutation Feature Importance Calculation:\n",
    "\n",
    "For each feature:\n",
    "    -Create a copy of the testing set.\n",
    "    -Permute the feature values and calculate the model's performance on the permuted dataset.\n",
    "    -Compute the difference between the baseline score and the permuted score.\n",
    "    -Average the importance values over the specified number of repeats.\n",
    "\n",
    "    -Create a DataFrame to Store Feature Importances:\n",
    "\n",
    "    Store the feature names and their corresponding importance values in a pandas DataFrame.\n",
    "    Sort the DataFrame by the importance values in descending order.\n",
    "\n",
    "    Plot the Top 10 Feature Importances:\n",
    "\n",
    "    Create a horizontal bar plot of the top 10 features based on their permutation importance values.\n",
    "    Label the x-axis as 'Permutation Feature Importance' and set the title of the plot to 'Top 10 Permutation Feature Importance'.\n",
    "    Invert the y-axis to have the most important feature at the top.\n",
    "\n",
    "    Return the Permutation Feature Importance DataFrame:\n",
    "\n",
    "# The function should return the DataFrame containing the feature names and their corresponding permutation importance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e7ac672-6d2c-4a78-85e1-36634a08b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_copy=test_data_logistic[features].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "670b9b29-8e3d-42f3-8c9d-1c833bed31b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp=[]\n",
    "imp_cal=np.zeros(X_test_copy.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e1b3faa5-3c89-497f-8e55-cb764855705b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m X_test_copy\u001b[38;5;241m.\u001b[39miloc[:, i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(X_test_copy\u001b[38;5;241m.\u001b[39miloc[:, i])\n\u001b[0;32m     11\u001b[0m permuted_score \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, model\u001b[38;5;241m.\u001b[39mpredict(X_test_copy))\n\u001b[1;32m---> 12\u001b[0m imp_cal[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mbaseline_score\u001b[49m \u001b[38;5;241m-\u001b[39m permuted_score\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Average importance over repeats\u001b[39;00m\n\u001b[0;32m     14\u001b[0m imp_cal[i] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m n_repeats\n",
      "\u001b[1;31mNameError\u001b[0m: name 'baseline_score' is not defined"
     ]
    }
   ],
   "source": [
    "# PFI calc\n",
    "  # Permutation feature importance\n",
    "from sklearn.metrics import accuracy_score\n",
    "n_repeats=10\n",
    "random_state=42\n",
    "for i in range(X_test_copy.shape[1]):  \n",
    "    # Permute the feature values\n",
    "    for _ in range(n_repeats):\n",
    "        np.random.seed(random_state)\n",
    "        X_test_copy.iloc[:, i] = np.random.permutation(X_test_copy.iloc[:, i])\n",
    "        permuted_score = accuracy_score(y_test, model.predict(X_test_copy))\n",
    "        imp_cal[i] += baseline_score - permuted_score\n",
    "        # Average importance over repeats\n",
    "        imp_cal[i] /= n_repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef526dff-26cd-430e-993d-22e8ca28ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a DataFrame to store the feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_test_copy.columns,\n",
    "    'Importance': imp_cal\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd0061-ab63-46b3-a5e8-50304c3cf64a",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Plot the top 10 feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_features = importance_df.head(10)\n",
    "plt.barh(top_features['Feature'], top_features['Importance'], color='skyblue')\n",
    "plt.xlabel('Permutation Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Top 10 Permutation Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd5905-95c4-46a2-8494-40d5b1289316",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d9abb-eeb0-4889-b045-c99c1ab54718",
   "metadata": {},
   "source": [
    "## To perform a K-Fold Cross validation\n",
    "\n",
    "K-Fold Cross Validation is a statistical technique to measure the performance of a machine learning model by dividing the dataset into K subsets of equal size (folds). The model is trained on K − 1 folds and tested on the last fold. This process is repeated K times, with each fold being used as the testing set exactly once. The performance of the model is then averaged over all K iterations to provide a robust estimate of its generalization ability.\n",
    "\n",
    "Cross-validation serves multiple purposes:\n",
    "\n",
    "Avoids Overfitting: Ensures that the model does not perform well only on the training data but generalizes to unseen data.\n",
    "\n",
    "Provides Robust Evaluation: Averages results over multiple iterations, reducing bias and variance in the performance metrics.\n",
    "\n",
    "Efficient Use of Data: Maximizes the utilization of the dataset, especially when the data size is limited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c3df85-6844-40db-9ddf-d71c18ca73bf",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/machine-learning/k-fold-cross-validation-in-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad58cb-1ff2-40b1-81eb-a24c712e05b6",
   "metadata": {},
   "source": [
    "\n",
    "    K Fold Cross Validation Gini\n",
    "\n",
    "    This function creates k fold cross-validation data sets and calculates Gini coefficient for logistic regression.\n",
    "\n",
    "    Parameters:\n",
    "    model_data : pandas DataFrame\n",
    "        The dataset.\n",
    "    default_flag : str\n",
    "        The column name of the default flag.\n",
    "    folds : int\n",
    "        The number of folds desired.\n",
    "    seed_value : int\n",
    "        A seed value for replicability.\n",
    "\n",
    "    Returns:\n",
    "    pandas DataFrame\n",
    "        A DataFrame containing Gini coefficients for each fold and their averages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d4f2b-28c7-4602-855a-ef092a90896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def k_fold_cross_validation_glm(model_data, default_flag, folds, seed_value):\n",
    "\n",
    "    np.random.seed(seed_value)\n",
    "    # Randomly shuffle the data\n",
    "    model_data = model_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Drop non-numeric columns\n",
    "    numeric_columns = model_data.select_dtypes(include=[np.number]).columns\n",
    "    model_data = model_data[numeric_columns]\n",
    "\n",
    "    # Initialize arrays to store Gini coefficients\n",
    "    gini_fold_train = []\n",
    "    gini_fold_test = []\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed_value)\n",
    "    for train_index, test_index in skf.split(model_data.drop(columns=[default_flag]), model_data[default_flag]):\n",
    "        train_data, test_data = model_data.iloc[train_index], model_data.iloc[test_index]\n",
    "\n",
    "        # Fit logistic regression model\n",
    "        model = LogisticRegression()\n",
    "        model.fit(train_data.drop(columns=[default_flag]), train_data[default_flag])\n",
    "\n",
    "        # Predict probabilities\n",
    "        train_pred_prob = model.predict_proba(train_data.drop(columns=[default_flag]))[:, 1]\n",
    "        test_pred_prob = model.predict_proba(test_data.drop(columns=[default_flag]))[:, 1]\n",
    "\n",
    "        # Calculate Gini coefficients\n",
    "        gini_train = 2 * roc_auc_score(train_data[default_flag], train_pred_prob) - 1\n",
    "        gini_test = 2 * roc_auc_score(test_data[default_flag], test_pred_prob) - 1\n",
    "\n",
    "        # Append Gini coefficients\n",
    "        gini_fold_train.append(gini_train)\n",
    "        gini_fold_test.append(gini_test)\n",
    "\n",
    "    # Calculate average Gini coefficients\n",
    "    avg_gini_train = np.mean(gini_fold_train)\n",
    "    avg_gini_test = np.mean(gini_fold_test)\n",
    "\n",
    "    # Create DataFrame to store results\n",
    "    fold_result = pd.DataFrame({\n",
    "        'Fold': range(1, folds + 1),\n",
    "        'GiniTrain': gini_fold_train,\n",
    "        'GiniTest': gini_fold_test\n",
    "    })\n",
    "    fold_result.loc[len(fold_result)] = ['Average', avg_gini_train, avg_gini_test]\n",
    "\n",
    "    return fold_result\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ff853-16b8-453e-b64b-c198680c9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df.drop(\"sector_risk_capped_0.99_mean_encoded\",axis =1,inplace=True)\n",
    "fold_result = k_fold_cross_validation_glm(reduced_df, \"default_flag\", 5, 1)\n",
    "fold_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e25afbd-abb2-429c-9c93-dfe9cf0c8bf3",
   "metadata": {},
   "source": [
    "The Statified K-Fold cross validation for the Logistic Regression Model Gives an average Gini value 0f 0.88 indicating the predictive power of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8a544-092e-4b18-89e4-703560bd898f",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af146f4-8efe-4d81-8056-f4850d5b31f7",
   "metadata": {},
   "source": [
    "## Random Forest Classification and the Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da269b7a-ee81-4f5d-9883-13b517e3148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_feature_importance(dataset,target_column,n_estimators):\n",
    "    X= dataset.drop(columns=[target_column])\n",
    "    y=dataset[target_column]\n",
    "    rfc=RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    rfc.fit(X,y)\n",
    "    feature_importance=rfc.feature_importances_\n",
    "    importance_df=pd.DataFrame({'Feature':X.columns,'Importance':feature_importance})\n",
    "    Feature_importance_df = importance_df.sort_values(by='Importance',ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Visualise Feature Importace\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.barh(importance_df['Feature'][:10],importance_df['Importance'][:10],color=\"green\")\n",
    "    plt.xlabel('Features',fontsize=15)\n",
    "    plt.ylabel('Importance',fontsize=15)\n",
    "    plt.title(\"Feature_Importance_RandomForest\")\n",
    "    plt.show()\n",
    "\n",
    "    return importance_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee82e6c-713c-4e1c-ad83-ef2361a2fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=train_data_corr_eliminated.select_dtypes(include=np.number)\n",
    "target_column='default_flag'\n",
    "\n",
    "Feature_importance_df = calculate_feature_importance(dataset, target_column, n_estimators=100)\n",
    "print(Feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb76136-08f7-4088-a561-0f5c47e2c761",
   "metadata": {},
   "source": [
    "The most important features in the prediction of default through the random forest classifier model are as shown in the plot above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e82c7-3e1d-478d-9b0d-337b1b3106b9",
   "metadata": {},
   "source": [
    "## SHAP values or SHAPELY additive explainations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0ea4f5-265a-4718-ad4b-6533605d3f15",
   "metadata": {},
   "source": [
    "Calculating these values can help decide the best set of features that contributes to predict the set of features\n",
    "to be used in in the Random Forest Regressor Model.\n",
    "SHAP values are model agnostic which means irrespective of the underlying model SHAP values explain the feature importance \n",
    "on the predictions of the target data\n",
    "lets apply the same on a logistic regression and a RandomForestRegressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e422753e-92fe-4806-bf52-9faf64486d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "# We have already split the dataset into test and train using train_test_split functionality from the model_selection in sklearn\n",
    "X= train_data_corr_eliminated.select_dtypes(include=np.number).drop('default_flag',axis=1)\n",
    "y=train_data_corr_eliminated[target_column]\n",
    "rfc=RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X,y)\n",
    "explainer = shap.TreeExplainer(rfc)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254730f3-12bb-448f-8084-3f2be2fc33fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_pd_true=shap_values[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4350f4a-5825-4a04-b81d-c466fadb46c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute SHAP values for feature importance\n",
    "shap_importance = pd.DataFrame(abs(shap_pd_true.mean(axis=0)), index=X.columns, columns=['SHAP Importance'])\n",
    "# Sort features by importance\n",
    "shap_importance = shap_importance.sort_values(by='SHAP Importance', ascending=False)\n",
    "shap_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb50d2a-1911-4a2c-a577-3021b7cde3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of SHAP importance\n",
    "# Plot SHAP feature importance and dependence plots for the first 10 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# SHAP feature importance plot for the top 10 features\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.barh(shap_importance.index[:10], shap_importance['SHAP Importance'].head(10), color='skyblue')\n",
    "plt.xlabel('SHAP Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Top 10 SHAP Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d722f7-08a9-4951-81df-49a296f5ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP dependence plots for the first 10 features\n",
    "for i, feature in enumerate(shap_importance.index[:10]):\n",
    "    shap.dependence_plot(feature, shap_pd_true, X, show=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9974912-f286-495e-9b9a-bfed8a3fc87e",
   "metadata": {},
   "source": [
    "# Permutation Feature Importance\n",
    "Permutation Feature Importance (PFI) is a model-agnostic technique to measure a feature's importance by shuffling its values and observing the resulting drop in model performance (score/accuracy), indicating how much the model relied on that feature for accurate predictions. If shuffling a feature significantly worsens the model's score, that feature is important; if the score barely changes, the feature is less crucial. It's great for black-box models but can struggle with highly correlated features, potentially underestimating their individual importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e3b6a-af51-4a4e-b90a-5925e6bb2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Baseline Score: for RandomForestClassifier model\n",
    "# Evaluate the model on the testing set (X_test and y_test) using the specified metric to get the baseline score.\n",
    "# Initialize an Array to Store Importances:\n",
    "# Create an array of zeros with the same length as the number of features to store the importance values.\n",
    "#Permutation Feature Importance Calculation:\n",
    "\n",
    "#For each feature:\n",
    "#Create a copy of the testing set.\n",
    "#Permute the feature values and calculate the model's performance on the permuted dataset.\n",
    "#Compute the difference between the baseline score and the permuted score.\n",
    "#Average the importance values over the specified number of repeats.\n",
    "\n",
    "# Create a DataFrame to Store Feature Importances:\n",
    "\n",
    "# Store the feature names and their corresponding importance values in a pandas DataFrame.\n",
    "# Sort the DataFrame by the importance values in descending order.\n",
    "\n",
    "# Plot the Top 10 Feature Importances:\n",
    "\n",
    "# Create a horizontal bar plot of the top 10 features based on their permutation importance values.\n",
    "# Label the x-axis as 'Permutation Feature Importance' and set the title of the plot to 'Top 10 Permutation Feature Importance'.\n",
    "# Invert the y-axis to have the most important feature at the top.\n",
    "\n",
    "# Return the Permutation Feature Importance DataFrame:\n",
    "\n",
    "# The function should return the DataFrame containing the feature names and their corresponding permutation importance values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf97d4f1-5e0e-42ba-b8d9-c01b20959b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_copy=test_data_corr_eliminated.copy()\n",
    "X_test_copy.drop(['date','year_month','default_flag'],axis =1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafcfacd-82c7-4aa5-8f87-ba653371d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_permutation_feature_importance(dataset,target_column,n_estimators):\n",
    "    X= dataset.drop(columns=[target_column])\n",
    "    y=dataset[target_column]\n",
    "    rfc=RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    rfc.fit(X,y)\n",
    "    \n",
    "dataset=train_data_corr_eliminated\n",
    "target_column='default_flag'\n",
    "n_estimators=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beefaead-b3dc-4cf7-b894-ff3b284e94d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat=rfc.predict(X_test_copy)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207cb46c-19e0-4b17-b5e6-e1c2a9c48ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "baseline_score=accuracy_score(y_test,y_hat)# Gives the Baseline score for PFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97272c0-ece9-41c8-917f-deb8d779bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp=[]\n",
    "imp_cal=np.zeros(X_test_copy.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c759b3-0dd4-4fb7-80e3-1b1280bed639",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set=X_test_copy.columns\n",
    "len(feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c9718-789e-44a5-8635-a8d20725c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PFI calc\n",
    "  # Permutation feature importance\n",
    "n_repeats=10\n",
    "random_state=42\n",
    "for i in range(X_test_copy.shape[1]):  \n",
    "    # Permute the feature values\n",
    "    for _ in range(n_repeats):\n",
    "        np.random.seed(random_state)\n",
    "        X_test_copy.iloc[:, i] = np.random.permutation(X_test_copy.iloc[:, i])\n",
    "        permuted_score = accuracy_score(y_test, rfc.predict(X_test_copy))\n",
    "        imp_cal[i] += baseline_score - permuted_score\n",
    "        # Average importance over repeats\n",
    "        imp_cal[i] /= n_repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7be760-6ffe-457d-955d-6ad001fc8354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a DataFrame to store the feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_test_copy.columns,\n",
    "    'Importance': imp_cal\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45c74b-fae4-42dd-9dfc-4e49b75c9858",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Plot the top 10 feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_features = importance_df.head(10)\n",
    "plt.barh(top_features['Feature'], top_features['Importance'], color='skyblue')\n",
    "plt.xlabel('Permutation Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Top 10 Permutation Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
